
\section{人工知能研究の歩みと人工ニューラルネットの誕生}
\label{sec:history}

\section{階層型ニューラルネットモデル}
\label{sec:hierarchical}

\subsection{脳神経網と人工ニューラルネット}
\label{sec:BNN-ANN}

\subsubsection{脳神経網}
\label{sec:neural-networks}

（脳神経網についてテキストを追加します。
説明項目：ニューロン、シナプス結合、シナプス可塑性、Hebbの法則、興奮、発火、抑制、スパイク、シナプス強度、軸索、軸索末端、樹状突起、膜電位）

\subsubsection{人工ニューラルネットの基本概念}
\label{sec:ann}


人工ニューラルネットは、
脳神経網を仮想的にコンピュータの中に再現し、
更に、生物の学習機能をプログラムとして実現することで、
生物による学習と同じ現象をコンピュータ内で発生させようという試みである。

誕生直後の人間は
言語や社会に関する知識を全く有しない誕生直後の「無垢の」状態にある。
この無垢の状態から、
外界からの刺激の「学習」を通して、言語や社会性を獲得し、成人へと成長する。
つまり、人間の知的能力の源泉は「学習」にある訳であるから、
\textbf{人間が学習するプロセスをコンピュータ内で再現することができれば、
コンピュータに知能を与えることができるであろう}という考え方が、
人工ニューラルネットの基本的なアイデアである。

しかしながら、
現代の脳科学では、人間の脳神経網で起こっている現象の全てを解明できている訳ではない。
また、仮に人間の脳神経網の仕組みを完全に解明できたとしても、
複雑な人間の脳神経の機能を忠実に再現することは現実的ではない可能性が高い。

科学では、
対象とする現象に解明できていない部分があったり、
現象が非常に複雑で忠実に再現することが困難であるような場合には、
本質と関係が薄いと思われる部分を思い切って捨象し、
メカニズムを単純化したモデルを考案して、
モデルを利用して近似的に現象を再現するという工夫を行う。
これを\textbf{モデル化}と呼ぶ。

例えば、
ボールを投げるとその軌跡は放物線を描くとされている。
ニュートン力学の運動方程式を用いて、各時刻におけるボールの空間座標を計算すれば、
ボールの軌跡が放物線になることを導くことができる。

しかしながら、
現実では、空気抵抗や、風の影響、地球の自転・公転の影響が存在するので、
これらの影響を計算に入れると、軌跡は正確には放物線にはならない。
しかし、これらの外的要因の影響が十分に小さいと考えても構わない場合には、
これらの外的要因の影響を捨象してモデルを定義し、
モデルからの帰結としてボールの軌跡は放物線であるとする。
「ボールの軌跡は放物線である」という主張は、あくまで現実の近似であり、
現実において（我々の活動が地球上に限られている限りにおいて）、
近似による誤差は無視しても構わない。

実は、ニュートン力学事態が、
より精密な力学理論である一般相対性理論や量子力学の近似であることが知られている。
つまり、現象の近似であるモデルに対して、更に、近似の理論を適用して、
「ボールの軌跡は放物線である」という結論を導いているのである。

脳神経網をコンピュータ内に構築する際にもモデル化を行う。
近年、だんだんと複雑の度合いを増しているものの、
人工ニューラルネットのモデルも非常に大胆な捨象に基づいて、
単純な原理で記述される。
この章では、
ニューロン単体のモデルと、
ネットワークのモデル、学習のモデルについて、それぞれの基本的な考え方を説明する。

人工ニューラルネットでは、
ニューロンをモデル化した概念を\textbf{ノード}と呼ぶのが通例である。
ニューロンは樹状突起において多数のニューロンと接続し、
シナプス結合を介して電気信号を受け取ることは前に述べたが、
ノードも他のノードから信号を受け取る。
ノード間の出力・入力の授受関係を\textbf{リンク}と呼ぶ。
脳神経細胞における軸索・シナプス結合・樹状突起という信号の伝達経路がリンクに相当する。

図~\ref{fig:node}では他のノードの出力を$x_1$から$x_n$で表している。
$n$はノード毎に固有であり、
ノードのネットワークを定める時に決定されるが、
$n$の設定に制限はない。
一方、信号$x_i$の値は、0か1の離散値であったり、
区間$[0, 1]$（0以上1以下の全ての実数）の値であったり、
任意の実数値であったりするなど、モデルの定義によって多様であるが、
これは後に述べる活性化関数の選択に依存する。

ニューロン$R$（ReceiverのR）にニューロン$S$（SenderのS）から信号が入力されるとき、
ニューロン$S$の軸索を経由して送られる電気信号の変化が、
ニューロン$R$の樹形特記末端での電位の変化を引き起こすが、
この電位の伝達の効率は、ニューロン$R$とニューロン$S$のの組み合わせによって異なり、
この伝達効率をシナプス強度と呼ぶことは既に述べた。
ニューロンモデルであるノードにおいては、シナプス強度は\textbf{重み}$w$によって表現する。
即ち、ノード$S$からノード$R$に信号が伝達されるとき、
ノードSの出力の強さが$x$であれば、ノードRが受け取る入力の強さは$wx$となる。
重み$w$はノード$S$とノード$R$の組み合わせ毎に独立であり、
ノード$S_1, \dots, S_n$がノード$R$に信号$x_1, \dots, x_n$を出力する時、
それぞれの入力を定める重みを独立の変数$w_i$で表す。
即ち、
ノード$R$が、
リンクで接続している全てのノードから受け取る入力の総和は、
$\displaystyle \sum_{i=1}^n w_ix_i$で計算される。

さて、ニューロン$R$においては、
入力された電気信号の累積が一定の閾値を超えると、
ニューロン$R$は発火し、信号$y$を出力する。
このメカニズムを数式で簡潔に表現するため、
バイアス$b$と活性化関数$f$を用いる。
現実では多様な活性化関数$f$が利用され、
特に、\ref{sec:loss-function}節で説明する損失関数を使った学習アルゴリズムでは、
活性化関数が微分可能であることを要求するが、
人工ニューラルネット研究の最初期に利用された活性化関数は階段関数であった。

以下では、
活性化関数を階段関数（正確にはヘヴィサイド階段関数）であるとして、
ニューロンモデルの記法について説明する（図~\ref{fig:node}）。
階段関数に基づくこのニューロンモデルは、
発明者の名前にちなんでマカロック・ピッツ（McCulloch–Pitts）モデルとも呼ばれるが、
1943年に発表され、以来、
人工ニューラルネット研究の基礎的な定式化となった。


\begin{enumerate}
\item
  今、入力$x_i$の重み付き和が予め定められた閾値$\theta$を超えると信号$y = 1$を出力し、
  $\theta$より小さいうちは信号$y = 0$を出力するようにしたい。
  最も直接的な方法は、関数$f_\theta(x)$を
  \[
    f_\theta(x) =
    \begin{cases}
      0, & \text{$x < \theta$の時}\\
      1, & \text{$x \ge \theta$の時}
    \end{cases}
  \]
  と定めて、活性化関数を$f_\theta$で定義する方法である。
  ノード$R$への入力の総和は$\displaystyle\sum_{i=1}^n w_i x_i$であるから、
  \[
    y = f_\theta\left(\sum_{i=1}^n w_i x_i\right)
  \]
  がノード$R$の出力となる。
\item
  上記の方法により活性化関数を明確に記述することができるが、
  計算上の不便さを含んでいる。
  \ref{sec:perceptron}節で詳しく述べるように、
  重み$w_1, \dots, w_n$と閾値$\theta$は学習の過程で変更されるパラメータであり、
  特に、損失関数と勾配降下法を用いた学習アルゴリズムでは、
  損失関数をこれらのパラメータ、特に、$\theta$で微分する必要がある。
  $\theta$が関数の定義に含まれていると、
  $\theta$を変更する時に活性化関数を変更しなければならなくなり、
  微分の計算も厄介になる。
  そこで、活性化関数を$\theta$に依存しないように固定し、
  $\theta$を活性化関数の引数の中に組み入れる工夫を行う。
  まず、活性化関数$f_\theta(x)$を
  \[
    f_0(x) =
    \begin{cases}
      0, & \text{$x < 0$の時}\\
      1, & \text{$x \ge 1$の時}\\
    \end{cases}
  \]
  に固定し、
  \[
    y = f_0\left(- \theta + \sum_{i=1}^n w_i x_i\right)
  \]
  で出力信号を定義する。
  \[
    f_0\left(- \theta + \sum_{i=1}^n w_i x_i\right) = f_\theta\left(\sum_{i=1}^n w_i x_i\right)
  \]
  が成り立つので、
  定義する関数に何ら変更はないことが分かる。
  
  人工ニューラルネットでの一般的な記法では、
  $-\theta$の符号が負であることを嫌って、
  \begin{equation}
    y = f_0\left(b + \sum_{i=1}^n w_i x_i\right)
    \label{eq:1}
  \end{equation}
  という記法を用いることが多い。
  $b = -\theta$を\textbf{バイアス}と呼ぶ。
  この表記のもとでは、
  \[
    f_0\left(b + \sum_{i=1}^n w_i x_i\right) =
    \begin{cases}
      0, & \text{$\displaystyle\sum_{i=1}^n w_i x_i < -b$の時}\\
      1, & \text{$\displaystyle\sum_{i=1}^n w_i x_i \ge -b$の時}\\
    \end{cases}
  \]
  が成り立ち、出力信号が入れ替わる閾値$\theta$の値は$-b$である。
\item
  2.の記法では、重み$w_i$とバイアス$b$の二種類の変数を区別するが、
  これを不便だと考える人がいる。
  特に、人工ニューラルネットの機能を数式で表現しようとする場合に、
  式が複雑になることを嫌う傾向がある。
  そのため、多くの教科書では、更に計算の便宜のよい簡潔な記法を用いることが多い。
  $w_0 = b$とし、実際の入力$x_1, \dots, x_n$に加えて、
  常に値$1$をとる仮想の入力$x_0 = 1$を想定すると、
  \[
    b + \sum_{i=1}^n w_i x_i = \sum_{i=0}^n w_i x_i
  \]
  と表記することができ、
  バイアスと重みを区別する必要がなくなり、数式での表現も簡潔になる。
  例えば、
  $\vc w = (w_0, \dots, w_n)$、
  $\vc x = (1, x_1, \dots, x_n)$とベクトル表記のもとでは、
  ノードへの入力の重み付き和を、
  \[
    \sum_{i=0}^n w_i x_i = \vc w\cdot\vc x
  \]
  と、ベクトルのドット積（内積）で簡潔に表記することができる。
\end{enumerate}

本書では、数式を用いた計算は必要出ない限りは避けることとしていることから、
数式で表現した時の簡潔さを追求するメリットはそれほど大きくない。
一方、バイアスと重みは物理的に異なる意味を持っており、
両者を区別して考えることは理解の上で有効であるという考えから、
2.の記法を用いることとする（図~\ref{fig:node}）。

\begin{itembox}{\bf コラム　階段関数}
  関数のグラフを描いた時、グラフが階段状になる関数のことを、
  一般に階段関数と呼ぶ。
  実数全体に定義された階段関数は、
  実数全体を必ずしも有限個とは限らない区間に分割し、
  同一の区間に属する$x$に対しては、同じ$f(x)$の値を割り当てた関数である。
  例えば、ガウス記号$[x]$（$\lfloor x\rfloor$と表記することもある）は、
  実数$x$を超えない整数を意味するが、
  関数としての$[x]$は階段関数である。
  実際、実数全体$\RR$は互いに交わりのない区間
  $[n, n+1)\ n = 0, \pm 1, \pm 2, \dots$の和となり、
  関数$[x]$は下式で定義される。
  \[
    [x] = n\quad \text{$x \in [n, n+1)$の時}
  \]
  階段関数$H(x)$が区間$(-\infty, 0)$、$[0,0]$、$(0, \infty]$に対して定義され、
  \[
    H_c(x) =
    \begin{cases}
      0, & \text{$x < 0$の時}\\
      c, & \text{$x = 0$の時}\\
      1, & \text{$x > 0$の時}\\
    \end{cases}
  \]
  を満たす時、\textbf{ヘヴィサイド階段関数}と呼ぶ。
  初期のニューラルネットモデルで利用される活性化関数は、
  $c = 0$の時のヘヴィサイド関数$H_0$であり、単位階段関数とも呼ばれる。
\end{itembox}

\begin{figure}
  \centering
  
  \caption{階段関数とヘヴィサイド階段関数}
  \label{fig:step-function}
\end{figure}

\begin{figure}
  \centering
  
  \caption{ノード}
  \label{fig:node}
\end{figure}

以上で、ニューロンの数理モデルであるノードを構成する要素、
入力・重み・バイアス・活性化関数について理解を得たものと思う。

次は、神経細胞網のモデルについて説明する。
神経細胞網はニューロンが互いに繋がり合ったネットワークであるので、
神経細胞網のモデルとしては、数学的構造のひとつであるグラフに基づく表現が自然である。
数学でいうグラフは、高校で習う「関数のグラフ」ではなく、
複数のノードがリンクを介して結合した構造のことを指す。
更に、リンクに向きが存在するとき、有向グラフと呼ぶ（図~\ref{fig:graph}）。

\begin{figure}
  \centering
  
  \caption{有向グラフ}
  \label{fig:graph}
\end{figure}

一方、神経細胞網における電気信号の流れは一方通行である。
即ち、ニューロン$S$で発生した電気信号は軸索を通り、
シナプス結合を介して、ニューロン$R$の樹状突起に伝達されるが、
逆方向、つまり、樹状突起から軸索に電気信号が伝達されることはない。
従って、
神経細胞網をグラフでモデル化するのであれば、
有向グラフを用いるべきである。
ノード$R$からノード$S$に信号が入力されるとき、
ノード$R$を始点、ノード$S$を終点とするリンクを定義する
（図~\ref{fig:directed-graph}）。

\begin{figure}
  \centering
  
  \caption{神経細胞網と有向グラフ}
  \label{fig:directed-graph}
\end{figure}

計算機による脳神経網の生理的機能のシミュレーションは、
以下の逐次計算の手順で実行される（図~\ref{fig:sequential-computation}）。
\begin{enumerate}
\item 他のノードからの入力を受けない（入ってくるリンクが存在しない）ノードを
  \textbf{始端ノード}と呼び、時刻$t = 1$において、
  全ての始端ノードの出力を式~(\ref{eq:1})によって計算する。
\item 時刻$t$では、時刻$t-1$で計算した出力を受け取る全てのノードにおいて、
  出力を式~(\ref{eq:1})によって計算する。
  この計算ステップを、出力の計算を行うノードが存在しなくなるまで、
  繰り返し実行する。
\item いずれのノードにも信号を出力しない（出て行くリンクが存在しない）ノードを
  \textbf{終端ノード}と呼び、
  終端ノードの出力をシミュレーションの計算結果とする。
\end{enumerate}

\begin{figure}
  \centering
  
  \caption{ノードの出力の逐次計算}
  \label{fig:sequential-computation}
\end{figure}

一方、何の制約も設けない一般的な有向グラフ上で、
逐次計算に基づくシミュレーションを実行すると、
以下に述べるような不都合が生じる可能性がある。

例えば、
図~\ref{fig:cycle}のように、
グラフ中にサイクル（閉路）が存在すると、
サイクル内のノードが無限に発火を繰り返し、
逐次計算が終了しないという事態が起こりえる。
このため、
神経細胞網をグラフとしてモデル化する際には、
サイクルが存在しないようにグラフを制限することが行われる。
サイクルを含まない有向グラフは、日本語では有向無閉路グラフ、
有向非巡回グラフなどと呼ばれ、
また、英語では\emph{directed acyclic graph}、頭文字をとって、DAGと略されたりする。

\begin{figure}
  \centering
  
  \caption{有向グラフ中のサイクル}
  \label{fig:cycle}
\end{figure}

また、図~\ref{fig:time-diference}のように、
いずれかの始点ノードからノード$R$に到達するパス（経路）が複数存在し、
かつ、その長さ（リンクの個数）が異なる時は、
逐次計算によるシミュレーションでは、
ノード$R$が時間差で発火
それに起因して、
グラフの終端ノードの出力が一意に定まらない。

\begin{figure}
  \centering
  
  \caption{時間差}
  \label{fig:time-diference}
\end{figure}

以上に述べたような弊害を避けるため、
人工ニューラルネット研究の初期においては、
神経細胞網のモデルであるグラフを次の条件を満たすように定義することは、
自然であると考えられた。
また、現在広く実用に供されている人工ニューラルネットの多くも、この条件を満足する。
\begin{itemize}
\item 始点ノードから特定のノードに到る複数のパスが存在する時、
  パスの長さ（パスを構成するリンクの個数）は互いに等しくなければならない。
\item 始端ノードから終端ノードへのパスの長さは一定である。
\end{itemize}
実は、
上記の条件を満足する有向グラフは、
自然に有向無閉路グラフとなり、
図~\ref{fig:hierarchical-model}に示すような階層グラフとなる。

\begin{itembox}{\bf コラム　階層グラフ}
  「始点と終点が一致するパスの長さが全て等しい」という条件から、
  ノードの階層を以下の手順で一意に定めることができる。
  始端ノードに番号$n = 0$を割り当て、
  始端ノード以外のノード（終端ノードも含む）については、
  いずれかの始点ノードからのパスの長さを$n$とする。
  条件から、ノードに割り当てられる$n$の値は一意に定まり、
  同じ$n$の値を公有するノード群が階層を共有する。
\end{itembox}

\begin{figure}
  \centering
  
  \caption{階層型ネットワークモデル}
  \label{fig:hierarchical-model}
\end{figure}

\ref{sec:non-hierarchical}章で説明するように、
階層グラフ以外のモデル化により神経細胞を研究する試みもなされているが、
現在華々しい成果を上げている深層学習のニューラルネットの研究は、
階層グラフに基づくニューラルネットの研究から発展したものである。

この章では、
神経細胞網を階層グラフでモデル化する\textbf{階層型ニューラルネットモデル}に焦点を当て、
ニューラルネットを理解する上で必要な概念を説明するとともに、
ニューラルネットにおける学習とは何かを理解する。

\subsection{単層パーセプトロンと誤り訂正学習}
\label{sec:perceptron}


1943年にウォーレン・マカロック（Warren McCulloch、1898年11月16日 - 1969年9月24日）と
ウォルター・ピッツ（Walter Pitts, 1923年4月23日 - 1969年5月14日）が
ニューロンモデルを発表したが、
パーセプトロンは、このニューロンモデルに基づく階層型ニューラルネットモデルである。
もっとも単純な構造を有するパーセプトロンである単層パーセプトロンは、
1958年にフランク・ローゼンブラッド
（Frank Rosenblatt、1928年7月11日 - 1971年7月11日）によって実装されている。
\textbf{単層パーセプトロン}は
ネットワーク構造を表現する階層グラフが1層のみからなるような構成を指し、
2層以上の階層グラフがニューラルネットを表現する構成は\textbf{多層パーセプトロン}と呼ぶ。

\subsubsection{パーセプトロンの構造}

\label{sec:structure-perceptron}

パーセプトロンにおいて、信号伝搬の最終層、つまり、
階層グラフにおける終端ノードからなる層を\textbf{出力層}と呼び、
出力層より下位の層を\textbf{隠れ層}と呼ぶ
（図~\ref{fig:perceptron}）。

出力層・隠れ層に加えて、
ネットワーク外部からの入力を隠れ層以降のノードに伝達するためのノードを設け、
「入力層」を定義することもあるが、
この表現では単層パーセプトロンは入力層と出力層の2層から構成されることになってしまう。
本書では、混乱のもとになると考えて、
「入力層」という表現を使用しないこととする。
単層パーセプトロンは英語の\emph{single-layered perceptron}の訳であるが、
活性化関数をヘヴィサイド階段関数に限定していることと併せて、
「単層パーセプトロン」の代わりに「単純パーセプトロン」という用語が用いられることがある事実は、
このような点に理由があると考えられる。

\begin{figure}
  \centering
  
  \caption{単層パーセプトロンと多層パーセプトロン}
  \label{fig:perceptron}
\end{figure}

本節では、単層パーセプトロンの説明を行うが、
同一の層に属するノードの機能は互いに独立であるので、
一個のノードからなる簡潔なパーセプトロンを理解できれば十分である。

ここでの説明の目的は、
学習アルゴリズムの例を通じて機械学習における学習原理を理解すること、
そして、学習アルゴリズムにおける重要な問題のひとつを理解することにある。
ここで取り上げる学習アルゴリズムは、「誤り訂正学習」と呼ばれる古典的なアルゴリズムである。

理解を容易にするために、
ただ一つのノードからなるパーセプトロンを考え、
更に、ノードへの入力は$x_1$と$x_2$の2個であると仮定する
（図~\ref{fig:perceptron-with-two-inputs}）。

\begin{figure}
  \centering
  
  \caption{2個の入力を持つパーセプトロン}
  \label{fig:perceptron-with-two-inputs}
\end{figure}

次に、
図~\ref{fig:data-sample-1}に示す
直線$\ell: 2x_1 - 4x_2 + 1 = 0$を境界として分布する二種類のデータを考える。
\begin{itemize}
\item 直線$\ell$の上側には、「1」をラベルに取り、■でプロットされる点が分布する。
\item 直線$\ell$の下側には、「0」をラベルに取り、●でプロットされる点が分布する。
\end{itemize}
データの集まりを\textbf{データセット}と呼ぶ。
この例では、5個のラベル1のデータ、5個のラベル0のデータ、
合計10個のデータからなるデータセットが与えられている。

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{fig/perc-plots.pdf}
  \caption{$2x_1 - 4 x_2 + 1 = 0$を境界とデータ分布の例}
  \label{fig:data-sample-1}
\end{figure}

今、図~\ref{fig:perceptron-with-two-inputs}のパーセプトロンの重みとバイアスを
\[
  w_1 = 2,\qquad w_2 = -4,\qquad b = 1
\]
とすると、信号$(x_1, x_2)$に対するパーセプトロンの出力は、
\begin{align*}
  y
  &
    = f_0(2x_1 + x_2 + 1)
    =
    \begin{cases}
      1, & \text{$2x_1 - 4x_2 + 1 > 0$の時}\\
      0, & \text{$2x_1 = 4x_2 + 1 < 0$の時}\\
    \end{cases}
\end{align*}
となる。
パーセプトロンの出力$y$は、
点のラベルの「予測」を表す。
表~\ref{tab:prediction-by-perceptron}に、
図~\ref{fig:data-sample-1}にプロットされた各データラベルと、
データをパーセプトロンに入力した時の出力を示す。

\begin{table}[htb]
  \centering
  \caption{データのラベルとパーセプトロンによる出力$y$}
  \label{tab:prediction-by-perceptron}
  
  \begin{tabular}{rrcc}
    \toprule
    $\boldsymbol{x_1}$ & $\boldsymbol{x_2}$ & \bf ラベル & $\boldsymbol y$ \\\midrule
    0.04 & 0.48 & 1 & 1\\
    0.32 & 0.69 & 1 & 1\\
    0.47 & 0.68 & 1 & 1\\
    0.72 & 0.85 & 1 & 1\\
    0.96 & 0.98 & 1 & 1\\
    0.04 & 0.03 & 0 & 0\\
    0.12 & 0.11 & 0 & 0\\
    0.3 & 0.11 & 0 & 0\\
    0.68 & 0.34 & 0 & 0\\
    0.87 & 0.46 & 0 & 0\\
    \bottomrule
  \end{tabular}
\end{table}

この例では、
データの生成方法と重みとバイアスの設定（$w_1 = 2, w_2 = -4, b = 1$）から、
ラベルと出力$y$が一致することは論理的に明らかであるが、
一般に、ラベルとパーセプトロンの出力が全てのデータにおいて一致する時、
\textbf{パーセプトロンはデータセットと無矛盾である}という。

さて、人間が図~\ref{fig:data-sample-1}のプロットを眺めれば、
2種類のデータの境界線である直線を見つけることは容易である。
一方、
機械学習の対象となるデータはより多数の値の組として表現される。
一つのデータを表現する値の個数を次元と呼ぶこともあるが、
次元は数千、数万に及ぶこともまれではない。
人間がデータのプロットを直感的に理解できる限界は2次元までで、
可視化の方法を工夫して3次元がぎりぎりである。
次元が数十、数百となれば、全くのお手上げで、計算機の助けを借りなければ困難である。

今、次元を$d$とし、
\[
  H: w_1x_1 + \dots + w_dx+d + b = 0
\]
を境界として分布する2種類のデータ群が与えられているとする。
各データは$d$個の値の組（ベクトル）として与えられるが、そのうち、
$m$個のデータ$(\alpha_{1,1}, \dots, \alpha_{1, d})$から
$(\alpha_{m,1}, \dots, \alpha_{m, d})$までは、
境界で二分される空間の片側の領域、即ち、
\[
  R_0: w_1x_1 + \dots + w_dx+d + b < 0
\]
で表される領域に分布するものとし、
ラベル「0」を付与する。
一方、
z残りの$n$個のデータ$(\beta_{1,1}, \dots, \beta_{1, d})$から
$(\beta_{n,1}, \dots, \beta_{n, d})$までは、
\[
  R_1: w_1x_1 + \dots + w_dx+d + b > 0
\]
で表される領域に分布するものとし、
ラベル「1」を付与する。

この時、我々は次の問題の解答を、計算機の助けを借りて求めたい。

\begin{screen}
  上記$m + n$個のデータが与えられている時、
  ラベル0のデータとラベル1のデータの間の
  境界$H$の方程式、即ち、係数$w_1, \dots, w_d, b$が未知である時、
  これらの係数の値をデータから計算せよ。
\end{screen}

数学的に明確に記述するならば、以下のようになる。

\begin{screen}
  $\alpha_{1,1}, \dots, \alpha_{m,d}$と$\beta_{1,1}, \dots, \beta_{n,d}$を定数、
  $w_1, \dots, w_d, b$を変数とする連立不等式
  \begin{center}
    \begin{tabular}{rcl}
      $w_1\alpha_{1,1} + w_2\alpha_{1,2} + \dots + w_d\alpha_{1,d} + b$ & $<$ & $0$
      \\
                                                                        & $\vdots$
      \\
      $w_1\alpha_{m,1} + w_2\alpha_{m,2} + \dots + w_d\alpha_{m,d} + b$ & $<$ & $0$
      \\
      $w_1\beta_{1,1} + w_2\beta_{1,2} + \dots + w_d\beta_{1,d} + b$ & $>$ & $0$
      \\
                                                                        & $\vdots$
      \\
      $w_1\beta_{m,1} + w_2\beta_{m,2} + \dots + w_d\beta_{m,d} + b$ & $>$ & $0$
    \end{tabular}
  \end{center}
  を、$w_1, \dots, w_d, b$に関して解け。
\end{screen}

この連立不等式を解く問題を、パーセプトロンの言葉で表現し直してみよう。
$w_1, \dots, w_d$を重み、$b$をバイアスとする単体のノードで構成される
単純なパーセプトロンを考える。
入力$(x_1, \dots, x_d)$に対するこのパーセプトロンの出力は
\[
  y = 
  \begin{cases}
    1, & \text{$w_1x_1 + \dots + w_dx_d + b > 0$の時}\\
    0, & \text{$w_1x_1 + \dots + w_dx_d + b < 0$の時}\\
  \end{cases}
\]
で定義される。
つまり、
\textbf{境界の方程式を定める係数$w_1, \dots, w_d$と$b$は
  パーセプトロンの重みとバイアスに一致する}ことが分かるので、
前述の境界$H$を求める問題は次の問題と同じである。

\begin{screen}
  上記$m+n$個のデータからなるデータセットが与えられている時、
  このデータセットと無矛盾なパーセプトロンを決定せよ。
\end{screen}

パーセプトロンを決定するとは、重みとバイアスの値を決定することである。

重みとバイアスの決定に使用されるデータセットを\textbf{訓練データセット}、
訓練データセット中のデータを\textbf{訓練データ}と呼び、
訓練データセットを用いて重みとバイアスを決定するプロセスを\textbf{学習}と呼ぶ。

より一般に、
\textbf{学習器}（ここではパーセプトロン）は
調整が可能なパラメータ（パーセプトロンの場合は重みとバイアス）を含んでおり、
訓練データと訓練データに付随するラベルに基づいて、
\textbf{パラメータを最適化する}計算手順が学習アルゴリズムである。

誤り訂正学習はパーセプトロンのための学習アルゴリズムであり、
パーセプトロンが訓練データセットと無矛盾となるように
重みとバイアス（パラメータ）を最適化する。
即ち、
訓練データにを入力した時のパーセプトロンの出力と、
訓練データに付随するラベルとが一致するように、
重み$w_1, \dots, w_d$とバイアス$b$を計算するアルゴリズムである。

以下では、誤り訂正学習アルゴリズムを説明するが、
その原理は
誤り訂正学習アルゴリズムに限定せず、
後に説明するより一般的な「損失関数と勾配降下法を用いた学習」を含めた
多くの学習アルゴリズムと共通である
（図~\ref{fig:error-correction}）。

\begin{itembox}{\bf 学習アルゴリズムの原理}
  \begin{enumerate}
  \item パラーメータに初期値を割り当てる。
  \item 訓練データに対する予測更新式により重みとバイアスを微調整する。
  \item 終了条件を満足するまでステップ2を繰り返す。
  \end{enumerate}
\end{itembox}

\begin{figure}
  \includegraphics[width=\linewidth]{fig/error-correction.pdf}
  \caption{誤り訂正学習の流れ}
  \label{fig:error-correction}
\end{figure}

一方、
「終了条件」は、誤り訂正学習と「損失関数と勾配降下法を用いた学習」では異なり、
誤り訂正学習の場合の「終了条件」は、
\textbf{パーセプトロンが訓練データセットと無矛盾である}こと、
即ち、
全ての訓練データについて、パーセプトロンの出力とラベルが一致することである

図~\ref{fig:data-sample-1}の10個の訓練データに対して誤り訂正学習を実際に実行した結果を、
図~\ref{fig:before-after}と表~\ref{tab:before-after}に示す。
この例では、$w_1 = 1, w_2 = 0, b = -0.5$が初期値として与えられ、
更新式により繰り返し更新された後、
$w_1 = -0.79, w_2 = 3.06, b = -1.3$に最適化される。
図~\ref{fig:before-after}と表~\ref{tab:before-after}に示すように、
学習後にはラベルとパーセプトロンの出力とは一致し、
パーセプトロンは訓練データに対して無矛盾であることが分かる。

\begin{figure}
  \centering
  \begin{minipage}{0.49\linewidth}\centering
    \includegraphics[width=\linewidth]{fig/perc-before.pdf}

    (a) 学習前の初期状態
  \end{minipage}
  \begin{minipage}{0.49\linewidth}\centering
    \includegraphics[width=\linewidth]{fig/perc-after.pdf}

    (b) 学習後の状態
  \end{minipage}
  \caption{学習のBefore-After}
  \label{fig:before-after}
\end{figure}

\begin{table}[htb]
  \centering
  \caption{学習前の出力$y$と学習後の出力$y$}
  \label{tab:before-after}
  
  \begin{tabular}{rrccc}
    \toprule
    $\boldsymbol{x_1}$ & \bf $\boldsymbol{x_2}$ & \bf ラベル & \bf $\boldsymbol y$（学習前） & \bf $\boldsymbol y$（学習後） \\\midrule
    0.04 & 0.48 & 1 & 0 & 1\\
    0.32 & 0.69 & 1 & 0 & 1\\
    0.47 & 0.68 & 1 & 0 & 1\\
    0.72 & 0.85 & 1 & 1 & 1\\
    0.96 & 0.98 & 1 & 1 & 1\\
    0.04 & 0.03 & 0 & 0 & 0\\
    0.12 & 0.11 & 0 & 0 & 0\\
    0.3 & 0.11 & 0 & 0 & 0\\
    0.68 & 0.34 & 0 & 1 & 0\\
    0.87 & 0.46 & 0 & 1 & 0\\
    \bottomrule
  \end{tabular}
\end{table}

図~\ref{fig:before-after}の結果は、
実際に誤り訂正学習を実際に実行した結果である。
重みとバイアスを何回か更新した結果得られた結果であり、
図~\ref{fig:change-parameters}に更新の履歴を示した。
図~\ref{fig:change-parameters}から、
12回更新を行った結果、訓練データセットと無矛盾なパーセプトロンが得られたことが分かる。
赤の破線はラベルと出力が異なる「不正解」の数の推移を示す。
12回の更新の後に初めて不正回数は0になっている。
同時に、
$w_1$（■）、$w_2$（◆）、$b$（●）が推移する様も観察することができる。

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{fig/perc-param-change.pdf}
  
  \caption{学習における重みとバイアスの変化}
  \label{fig:change-parameters}
\end{figure}

さて、以下では、誤り訂正学習における更新式と、
誤り訂正学習におけるパラメータ更新の計算を逐次的に追う。
一般に、学習器のパラメータの更新のタイミングには、以下の3つの方式がある。

\begin{description}
\item[オンライン学習]
  訓練データを順に学習器に入力し、出力が得られる都度、更新式を適用する。
\item[バッチ学習]
  全訓練データを学習器に入力し、全ての出力が得られるタイミングで、
  更新式を適用する。
\item[ミニバッチ学習]
  オンライン学習とバッチ学習の中間の学習方法である。
  訓練データセットを複数のグループに分割し、
  個別のグループの訓練データを学習器に入力し、
  出力が得られるタイミングで、更新式を適用する。
  各訓練データのグループを\textbf{ミニバッチ}と呼ぶ。
\end{description}

オンライン学習は、学習に使用するメモリーが小さくてすむ一方、
学習に必要な時間が大きくなると言うデメリットがある。
バッチ学習はその逆で、
学習に必要な時間は比較的小さく押さえ有られる一方、
大きなメモリーが必要となる。
ニューラルネットを利用した学習では、
膨大な大きさの訓練データセットを利用して学習を実行しなければならない場面が多く、
使用メモリー量と学習時間のトレードオフに対して適切なバランスを設定する必要がある。
特に、
近年ニューラルネットの計算に広く使われるGPU（Graphic Processing Unit）を使用する場合、
GPUのメモリーに展開できる最大量の計算データを一括して計算することが可能であると、
計算効率が飛躍的に改善されることが知られている。
そのため、
ミニバッチ学習により、
メモリー量の制約と計算効率とを両立させることは重要である。

さて、以下では、
オンライン学習とバッチ学習のそれぞれについて、
誤り訂正学習の更新式を示し、
具体的な例を用いて、誤り訂正学習のプロセスを逐次的に観察する。

図~\ref{fig:data-sample-1}の例では訓練データの個数が多すぎるので、
表~\ref{tab:and}に示す4個の訓練データからなる訓練データセットを考える。
それぞれのデータの値は$(x_1, x_2) = (0, 0), (0, 1), (1, 1), (1, 0)$であり、
ラベルは$x_1$と$x_2$の論理積$x_1\land x_2$と一致するとする。
\begin{table}
  \centering
  \caption{AND演算のためのデータセット}
  \label{tab:and}
  \begin{tabular}{rrc}
    \toprule
    $x_1$ & $x_2$ & ラベル（$x_1\land x_2$）\\
    \midrule
    0 & 0 & 0\\
    0 & 1 & 0\\
    1 & 1 & 1\\
    1 & 0 & 0\\
    \bottomrule       
  \end{tabular}
\end{table}

図~\ref{fig:online-1}では、
表~\ref{tab:and}の訓練データを、
ラベル0の点は●、ラベル1の点は■でプロットした。
この訓練データセットを利用した例は、
パーセプトロンで論理積（AND）演算を実現することが可能であることを示す古典的な例である。

図~\ref{fig:online-1}では、
重みとバイアスの初期値を$w_1 = 1, w_2 = 0, b = -0.5$として、
初期値が定める直線$x = 0.5$も併せて示している。
この直線の左側の点を入力すると出力0、右側の点を入力すると出力1を得るので、
初期状態において、不正解の数は1個になる。

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{fig/online-1.pdf}
  \caption{訓練データと初期パラメータ}
  \label{fig:online-1}
\end{figure}

\subsubsection{オンライン学習手順}
\label{sec:online-error-correction}

訓練データ$(x_1, \dots, x_n)$を
重みとバイアスの現在の値が$w_1, \dots, w_d$と$b$であるパーセプトロンに入力すると、
\[
  y = f_0\left(b + \sum_{i=1}^d w_ix_i\right)
\]
により、出力が計算される。
一方、
訓練データのラベルを$t$で表す時、
重みとバイアスは以下の更新式により更新される。

\begin{itembox}{\bf 誤り訂正学習における更新式（オンライン学習）}
  \begin{align}
    \label{eq:2}
    w_i & \leftarrow w_i + \eta (t - y) x_i,
    \qquad i = 1, \dots, d
    \\\label{eq:3}
    b & \leftarrow b + \eta (t - y)
  \end{align}
\end{itembox}


式~(\ref{eq:2})は、
現在の重みの値$w_i$に$\eta (t - y) x_i$を加えた値を新しい重みの値として、
古い重みの値を置き換えることを意味する。
同様に、
式~(\ref{eq:3})は、
現在のバイアスの値$b$に$\eta (t - y)$を加えた値を新しいバイアスの値として、
古いバイアス
の値を置き換えることを意味する。

ここで、$\eta$は\textbf{学習率}と呼ばれる定数で、
1回あたりの更新における重みとバイアスの微調整の幅を調整するパラメータである。
一般に、学習率の値が小さいとデータセットと無矛盾な重みとバイアスの値に到達するまでに
長い時間がかかり、学習率の値が大きいと重みとバイアスの値が振動して、
適切な値に到達できない可能性がある。
そのため、学習率を適正な値に設定する必要が出てくる。

更新式~(\ref{eq:2})と~(\ref{eq:3})において
$t = y$が成り立つ場合、即ち、
\textbf{パーセプトロンの出力とラベルが一致する時には、
  重み・バイアスともに値が更新されない}
ことに注意しておこう。
$t - y = 0$が成立するということは、
$t$をラベルとして持ち、$y$を出力とする訓練データは、
現在のパーセプトロンと矛盾しないからである。

図~\ref{fig:online-1}の初期パラメータから出発して、
各訓練データ（各点）を順番に評価し、
式(\ref{eq:2})と~(\ref{eq:3})を用いて重み$w_1, w_2$とバイアスを
更新する計算を追っていく。
\begin{itemize}
\item データは$(0, 0) \to (0, 1) \to (1, 1) \to (1, 0)\to (0, 0)$の順で
  循環的に評価する。
\item 学習率は$\eta = 0.4$とする。 
\end{itemize}

\begin{enumerate}\renewcommand\labelenumi{\textbf{ステップ\arabic{enumi}. }}
\item \textbf{$\boldsymbol{(0, 0)}$を評価
    （$\boldsymbol{b, w_1, w_2 = -0.5, 1, 0}$）. }
  訓練データのラベルは$t = 0$。
  一方、
  \[
    b + w_1x_1 + w_2x_2 =
    -0.5 + 1\times 0 + 0\times 0 < 0
  \]
  より、パーセプトロンの出力$y$は$0$である。
  $t - y = 0$が成り立つので、重みとバイアスの値は更新されない。
\item \textbf{$\boldsymbol{(0, 1)}$を評価
    （$\boldsymbol{b, w_1, w_2 = -0.5, 1, 0}$）. }
  訓練データのラベルは$t = 0$で、
  パーセプトロンの出力$y$の値は
  \[
    b + w_1x_1 + w_2x_2 =
    -0.5 + 1\cdot 0 + 0\cdot 1 < 0
  \]
  より$0$であるので、
  重みとバイアスの値は更新されない。
\item \textbf{$\boldsymbol{(1, 1)}$を評価
    （$\boldsymbol{b, w_1, w_2 = -0.5, 1, 0}$）. }
  訓練データのラベルは$t = 1$で、
  パーセプトロンの出力$y$の値は
  \[
    b + w_1x_1 + w_2x_2 =
    -0.5 + 1\cdot 1 + 0\cdot 1 > 0
  \]
  より$1$であるので、
  重みとバイアスの値は更新されない。
\item\label{item:1}
  \textbf{$\boldsymbol{(1, 0)}$を評価
    （$\boldsymbol{b, w_1, w_2 = -0.5, 1, 0}$）. }
  訓練データのラベルは$t = 0$で、
  パーセプトロンの出力$y$の値は
  \[
    b + w_1x_1 + w_2x_2 =
    -0.5 + 1\cdot 1 + 0\cdot 1 > 0
  \]
  より$1$となる。
  $t - y = 0 - 1 = -1$であるので、
  式(\ref{eq:2})と~(\ref{eq:3})より、各パラメータは次のように更新される。
  \begin{align*}
    &
      b = -0.5 + 0.4\cdot (0 - 1) = - 0.9
    \\&
    w_1 = 1 + 0.4\cdot (0 - 1)\cdot 1 = 0.6
    \\&
    w_2 = 0 + 0.4\cdot (0 - 1)\cdot 0 = 0
  \end{align*}
  結果、$b + w_1x_1 + w_2x_2$が表す直線の方程式は$x_1 = 1.5$となる
  （図~\ref{fig:online-2}）。
  
  \begin{figure}
    \centering
    \includegraphics[width=\linewidth]{fig/online-2.pdf}
    
    \caption{ステップ~\ref{item:1}の評価後のグラフ}
    \label{fig:online-2}
  \end{figure}
\item
  \textbf{$\boldsymbol{(0, 0)}$を評価
    （$\boldsymbol{b, w_1, w_2 = -0.9, 0.6, 0}$）. }
  訓練データのラベルは$0$、
  パーセプトロンに入力した時の出力も$y = 0$であるので、
  重みとバイアスは更新されない。
\item
  \textbf{$\boldsymbol{(0, 1)}$を評価
    （$\boldsymbol{b, w_1, w_2 = -0.9, 0.6, 0}$）. }
  訓練データのラベルは$0$、
  パーセプトロンに入力した時の出力も$y = 0$であるので、
  重みとバイアスは更新されない。
\item\label{item:2}
  \textbf{$\boldsymbol{(1, 1)}$を評価
    （$\boldsymbol{b, w_1, w_2 = -0.9, 0.6, 0}$）. }
  訓練データのラベルは$t = 1$、
  パーセプトロンの出力は$y = 0$であるので、
  式(\ref{eq:2})と~(\ref{eq:3})より、各パラメータは次のように更新される。
  \begin{align*}
    &
      b = -0.9 + 0.4\cdot (1 - 0) = - 0.5
    \\&
    w_1 = 0.6 + 0.4\cdot (1 - 0)\cdot 1 = 1
    \\&
    w_2 = 0 + 0.4\cdot (1 - 0)\cdot 1 = 0.4
  \end{align*}
  結果、$b + w_1x_1 + w_2x_2$が表す直線の方程式は$10 x_1 + 4 x_2 = 5$となる
  （図~\ref{fig:online-3}）。

  \begin{figure}
    \centering
    \includegraphics[width=\linewidth]{fig/online-3.pdf}
    
    \caption{ステップ~\ref{item:2}の評価後のグラフ}
    \label{fig:online-3}
  \end{figure}
\item \label{item:3}
  \textbf{$\boldsymbol{(1, 0)}$を評価
    （$\boldsymbol{b, w_1, w_2 = -0.5, 1, 0.4}$）. }
  訓練データのラベルは$t = 0$、
  パーセプトロンの出力は$y = 1$であるので、
  式(\ref{eq:2})と~(\ref{eq:3})より、各パラメータは次のように更新される。
  \begin{align*}
    &
      b = -0.5 + 0.4\cdot (0 - 1) = - 0.9
    \\&
    w_1 = 1 + 0.4\cdot (0 - 1)\cdot 1 = 0.6
    \\&
    w_2 = 0.4 + 0.4\cdot (0 - 1)\cdot 0 = 0.4
  \end{align*}
  結果、$b + w_1x_1 + w_2x_2$が表す直線の方程式は、$6 x_1 + 4 x_2 = 9$となる
  （図~\ref{fig:online-4}）。

  \begin{figure}
    \centering
    \includegraphics[width=\linewidth]{fig/online-4.pdf}
    
    \caption{ステップ~\ref{item:3}の評価後のグラフ}
    \label{fig:online-4}
  \end{figure}

\item
  \textbf{$\boldsymbol{(0, 0)}$を評価
    （$\boldsymbol{b, w_1, w_2 = -0.9, 0.6, 0.4}$）. }
  訓練データのラベルは$0$、
  パーセプトロンに入力した時の出力も$y = 0$であるので、
  重みとバイアスは更新されない。
\item
  \textbf{$\boldsymbol{(0, 1)}$を評価
    （$\boldsymbol{b, w_1, w_2 = -0.9, 0.6, 0.4}$）. }
  訓練データのラベルは$0$、
  パーセプトロンに入力した時の出力も$y = 0$であるので、
  重みとバイアスは更新されない。
\item
  \textbf{$\boldsymbol{(1, 1)}$を評価
    （$\boldsymbol{b, w_1, w_2 = -0.9, 0.6, 0.4}$）. }
  訓練データのラベルは$1$、
  パーセプトロンに入力した時の出力も$y = 1$であるので、
  重みとバイアスは更新されない。
\item
  \textbf{$\boldsymbol{(1, 0)}$を評価
    （$\boldsymbol{b, w_1, w_2 = -0.9, 0.6, 0.4}$）. }
  訓練データのラベルは$0$、
  パーセプトロンに入力した時の出力も$y = 0$であるので、
  重みとバイアスは更新されない。
  この時点で、重みとバイアスを変更することなく、
  訓練データを一巡したので、
  この後評価を継続しても、パラメータが更新されることはない。
\end{enumerate}

最終的に、重みとパラメータの最適値として、
\begin{align*}
  &
    b = -0.9
  \\&
  w_1 = 0.6
  \\&
  w_2 = 0.4
\end{align*}
を得、
このパラメータが決定するパーセプトロンは、
以下のように、正しくラベルを出力することを確かめることが出来る。
\begin{align*}
  &
    f_0(-0.9 + 0.6 \cdot 0 + 0.4 \cdot 0) = f_0(-0.9) = 0
  \\&
  f_0(-0.9 + 0.6 \cdot 0 + 0.4 \cdot 1) = f_0(-0.5) = 0
  \\&
  f_0(-0.9 + 0.6 \cdot 1 + 0.4 \cdot 1) = f_0(0.1) = 1
  \\&
  f_0(-0.9 + 0.6 \cdot 1 + 0.4 \cdot 0) = f_0(-0.3) = 0
\end{align*}

図~\ref{fig:online-change}に、
上記ステップの実行による重みとバイアスの変化を示す。
ステップ9〜12の4ステップでパラメータの値に変化がないのは、
4個全ての訓練データについて
ラベル$t$とパーセプトロンの出力$y$が一致することを確認しているからである。

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{fig/online-change.pdf}
  \caption{パラメータの更新（オンライン学習）}
  \label{fig:online-change}
\end{figure}



\subsubsection{バッチ学習の手順}
\label{sec:batch-error-correction}

バッチ学習とミニバッチ学習では、
複数の訓練データを入力とするパーセプトロンの出力を一括して計算し、
重みとバイアスの更新を一時に実行する。
今、
一回のパラメータの更新で評価する訓練データを$\vc x[1], \dots, \vc x[k]$、
対応するラベルを$y[1], \dots, y[k]$とする。
各訓練データ$\vc x[j]$は、$d$個の値からなるベクトルで、
\[
  \vc x[j] = (x_1[j], \dots, x_d[j])
\]
と表記されるとする。
この時、
重み$w_1, \dots, w_d$とバイアス$b$の更新式は、
以下のように与えられる。

\begin{screen}
  \begin{align}
    \label{eq:4}
    w_i & \leftarrow w_i + \eta\left(\sum_{j=1}^k
          \left(t[j] - y[j]\right) x_i[j]\right),
    \qquad i = 1, \dots, d\\
          \label{eq:5}
    b & \leftarrow b + \eta\left(\sum_{j=1}^k
        \left(t[j] - y[j]\right)\right)
  \end{align}
\end{screen}

\newpage
\begin{itembox}{\bf コラム　更新式~(\ref{eq:4})の行列による表現}
  行列を使って表現すると、
  更新式~(\ref{eq:4})を簡潔に表現できるようになる。
  個々の訓練データを行ベクトルで表し、
  それを積み重ねて、$k \times d$の行列$\mathrm X$を以下のように定める。
  \[
      \mathrm X =
      \begin{bmatrix}
        x_1[1] & \dots & x_d[1] \\
        \vdots & \ddots & \vdots \\
        x_1[k] & \dots & x_d[k] \\
      \end{bmatrix}
  \]
  また、ベクトル$\vc w, \vc t, \vc y$を以下のように定める。
  \begin{align*}
    &
      \vc w = \begin{pmatrix} w_1 & \cdots & w_d \end{pmatrix}
    \\&
      \vc t = \begin{pmatrix} t[1] & \cdots & t[k] \end{pmatrix}
    \\&
      \vc y = \begin{pmatrix} y[1] & \cdots & y[k] \end{pmatrix}
  \end{align*}
  この表記のもとで、
  更新式~(\ref{eq:4})は以下のように表記することができる。
  \[
    \vc w \leftarrow
    \vc w + \eta(\vc t - \vc y) \mathrm X
  \]
  % \[
  %   \begin{pmatrix} w_1 & \dots & w_d \end{pmatrix} \leftarrow
  %   \begin{pmatrix} w_1 & \dots & w_d \end{pmatrix} + \eta
  %   \begin{pmatrix} t[1] - y[1] & \dots & t[k] - y[k]\\ \end{pmatrix} \mathrm X
  % \]
  Pythonなどのプログラミング言語でNumpyライブラリを使用する場合、
  行列とベクトルの計算を簡潔な手順で記述できるので、
  行列による表現は実用上でも意義がある。
\end{itembox}

\newpage

以下では、
表~\ref{tab:and}と図~\ref{fig:online-1}で示した訓練データセットを例に用いて、
バッチ学習の手順を示す。
訓練データは4個であるので、
\[
  \vc x[1] = (0, 0), \quad
  \vc x[2] = (0, 1), \quad 
  \vc x[3] = (1, 1), \quad 
  \vc x[4] = (1, 0) 
\]
と表す。
また、ラベルは、
\[
  t[1] = 0, \quad
  t[2] = 0, \quad 
  t[3] = 1, \quad 
  t[4] = 0
\]
となるので、更新式は以下で与えられる。
\begin{align*}
  &
      w_1 \leftarrow w_1 + \eta \left(
    ( 0 - y[1]) \cdot 0
     + (0 - y[2]) \cdot 0
     + (1 - y[3]) \cdot 1
     + (0 - y[4]) \cdot 1
      \right)
    \\&
      w_2 \leftarrow w_2 + \eta \left(
    ( 0 - y[1]) \cdot 0
     + (0 - y[2]) \cdot 1
     + (1 - y[3]) \cdot 1
     + (0 - y[4]) \cdot 0
      \right)
    \\&
      b \leftarrow b + \eta \left(
    ( 0 - y[1])
     + (0 - y[2])
     + (1 - y[3])
     + (0 - y[4])
      \right)
\end{align*}
以下のステップの計算では、この更新式を利用する。

\begin{enumerate}\renewcommand\labelenumi{\textbf{ステップ\arabic{enumi}. }}
\item \textbf{$\boldsymbol{b, w_1, w_2 = -0.5, 1, 0}$. }\label{item:4}
  式~(\ref{eq:4})と~(\ref{eq:5})により、
  重みとバイアスは、以下のように更新される。
  \begin{align*}
    &
      w_1 = 1 + 0.4 \left(
    ( 0 - 0) \cdot 0
     + (0 - 0) \cdot 0
     + (1 - 1) \cdot 1
     + y(0 - 1) \cdot 1
      \right) = 0.6
    \\&
      w_2 = 0 + 0.4 \left(
    ( 0 - 0) \cdot 0
     + (0 - 0) \cdot 1
     + (1 - 1) \cdot 1
     + (0 - 1) \cdot 0
      \right) = 0
    \\&
      b = -0.5 + 0.4 \left(
    ( 0 - 0)
     + (0 - 0)
     + (1 - 1)
     + (0 - 1)
      \right) = -0.9
  \end{align*}

  更新された後の重みとバイアスによる直線は$x_1 = 1.5$となる
  （図~\ref{fig:batch-2}）。

  \begin{figure}
    \centering
    \includegraphics[width=\linewidth]{fig/batch-2.pdf}
    \caption{ステップ~\ref{item:4}の評価後のグラフ}
    \label{fig:batch-2}
  \end{figure}
  
\item \textbf{$\boldsymbol{b, w_1, w_2 = -0.9, 0.6, 0}$. }\label{item:5}
  式~(\ref{eq:4})と~(\ref{eq:5})により、
  重みとバイアスは、以下のように更新される。
  \begin{align*}
    &
      w_1 = 0.6 + 0.4 \left(
      ( 0 - 0) \cdot 0
     + (0 - 0) \cdot 0
     + (1 - 0) \cdot 1
     + (0 - 0) \cdot 1
      \right) = 1
    \\&
      w_2 = 0 + 0.4 \left(
    ( 0 - 0) \cdot 0
     + (0 - 0) \cdot 1
     + (1 - 0) \cdot 1
     + (0 - 0) \cdot 0
      \right) = 0.4
    \\&
      b = -0.9 + 0.4 \left(
    ( 0 - 0)
     + (0 - 0)
     + (1 - 0)
     + (0 - 0)
      \right) = -0.5
  \end{align*}

  更新された後の重みとバイアスによる直線は$10x_1 + 4x+2 = 5$となる
  （図~\ref{fig:batch-2}）。

  \begin{figure}
    \centering
    \includegraphics[width=\linewidth]{fig/batch-3.pdf}
    \caption{ステップ~\ref{item:5}の評価後のグラフ}
    \label{fig:batch-3}
  \end{figure}
\item \textbf{$\boldsymbol{b, w_1, w_2 = -0.5, 1, 0.4}$. }\label{item:6}
  式~(\ref{eq:4})と~(\ref{eq:5})により、
  重みとバイアスは、以下のように更新される。
  \begin{align*}
    &
      w_1 = 1 + 0.4 \left(
      (0 - 0) \cdot 0
     + (0 - 0) \cdot 0
     + (1 - 1) \cdot 1
     + (0 - 1) \cdot 1
      \right) = 0.6
    \\&
      w_2 = 0.4 + 0.4 \left(
    (0 - 0) \cdot 0
     + (0 - 0) \cdot 1
     + (1 - 1) \cdot 1
     + (0 - 1) \cdot 0
      \right) = 0.4
    \\&
      b = -0.5 + 0.4 \left(
    ( 0 - 0)
     + (0 - 0)
     + (1 - 1)
     + (0 - 1)
      \right) = -0.9
  \end{align*}

  更新された後の重みとバイアスによる直線は$6x_1 + 4x_2 = 9$となる
  （図~\ref{fig:batch-2}）。

  \begin{figure}
    \centering
    \includegraphics[width=\linewidth]{fig/batch-4.pdf}
    \caption{ステップ~\ref{item:6}の評価後のグラフ}
    \label{fig:batch-3}
  \end{figure}
\item \textbf{$\boldsymbol{b, w_1, w_2 = -0.9, 0.6, 0.4}$. }\label{item:7}
  全てのデータにおいて、ラベル$t$とパーセプトロンの出力$y$は一致するので、
  以下に示すように重みとバイアスは更新されない。
  \begin{align*}
    &
      w_1 = 0.6 + 0.4 \left(
      (0 - 0) \cdot 0
     + (0 - 0) \cdot 0
     + (1 - 1) \cdot 1
     + (0 - 0) \cdot 1
      \right) = 0.6
    \\&
      w_2 = 0.4 + 0.4 \left(
    (0 - 0) \cdot 0
     + (0 - 0) \cdot 1
     + (1 - 1) \cdot 1
     + (0 - 0) \cdot 0
      \right) = 0.4
    \\&
      b = -0.9 + 0.4 \left(
    ( 0 - 0)
     + (0 - 0)
     + (1 - 1)
     + (0 - 0)
      \right) = -0.9
  \end{align*}
\end{enumerate}

図~\ref{fig:batch-change}に、
上記ステップの実行による重みとバイアスの変化を示す。

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{fig/batch-change.pdf}
  \caption{パラメータの更新（バッチ学習）}
  \label{fig:batch-change}
\end{figure}

\subsubsection{単層パーセプトロンと誤り訂正学習の限界}
\label{sec:limit-error-correction}

誤り訂正学習では、
ラベルの異なる訓練データを分離するような超平面を探すことから、
\textbf{分離超平面}がそもそも存在しないような分類問題を解くことは出来ない。
次元$d$の空間、即ち、$d$個の座標$(x_1, \dots, x_d)$で点が特定されるような空間において、
定数$a_0, \dots, a_d$に対して、
\[
  H: a_0 + a_1 x_1 + \dots + a_d x_d = 0
\]
を満足する点$(x_1, \dots, x_d)$の集合を超平面と呼ぶ。
$d = 2$、即ち、平面空間における超平面は直線、
$d = 3$、即ち、3次元空間における超平面は平面になる。

ラベルの異なるデータの境界が超平面になるという条件を満たす分類問題を、
\textbf{線形分離問題}と呼ぶ。
単層パーセプトロンと誤り訂正学習では、線形分離問題しか解くことができず、
これは単層パーセプトロンと誤り訂正学習の限界と認識されている。

単層パーセプトロンで解くことができない重要な問題の例として、
XOR演算問題がある（表~\ref{tab:xor}。
即ち、
入力$x_1$と$x_2$に対して、
排他的論理和$x_1\oplus x_2$を出力する単層パーセプトロンは存在しない。
図~\ref{fig:xor}からも直感的に分かるように、
ラベル1の点（■）とラベル0の点（●）を分離するように直線を引くことはできない、
つまり、XOR演算問題は線形分離問題ではないからである。


\begin{table}
  \centering
  \caption{XOR演算のためのデータセット}
  \label{tab:xor}
  \begin{tabular}{rrc}
    \toprule
    $x_1$ & $x_2$ & ラベル（$x_1\oplus x_2$）\\
    \midrule
    0 & 0 & 0\\
    0 & 1 & 1\\
    1 & 1 & 0\\
    1 & 0 & 1\\
    \bottomrule       
  \end{tabular}
\end{table}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{fig/xor.pdf}
  \caption{XOR演算（線形分離でない問題の例）}
  \label{fig:xor}
\end{figure}

\begin{itembox}{\bf コラム　XOR演算問題が線形分離でないことの証明}
  直線$\ell: ax + by + c = 0$が、点$(0, 0)$と$(0, 1)$、
  点$(0, 0)$と$(1, 0)$を分離するならば、
  $(0, 0)$と$(1, 1)$も分離することを示す。
  $\ell$が点$(0, 0)$と$(0, 1)$を分離するための条件は、
  \[
      0 > (a\cdot 0 + b\cdot 0 + c)(a\cdot 1 + b\cdot 0 + c)
      = c(a + c)
    \]
  であり、また、点$(0, 0)$と$(1, 0)$を分離する条件は、
  \begin{align*}
    &
    \\&
    0 > (a\cdot 0 + b\cdot 0 + c)(a\cdot 1 + b\cdot 0 + c)
    = c(b + c)
  \end{align*}
  であるので、2つの不等式の右辺同士・左辺同士の和から、不等式
  \begin{align*}
    0 &> c(a + c) + c(a + c)
        = ac + bc + 2c^2
    \\&
        \ge ac + bc + c^2
    = (a\cdot 0 + b\cdot 0 + c)(a\cdot 1 + b\cdot 1 + c)
  \end{align*}
  が成り立ち、
  $\ell$は点$(0, 0)$と$(1, 1)$を分離することが分かる。
\end{itembox}

パーセプトロンの「計算能力」を評価する上で、
論理演算を実行できるかを調べることは重要である。
先の例で、
誤り訂正学習により、
AND演算を実行する単層パーセプトロンを学習することが可能であることを見た。
同様に、
OR演算を実行する単層パーセプトロン、
NOT演算を実行する単層パーセプトロンを学習することも可能である。
その一方で、
XOR演算を実行する単層パーセプトロンが存在しない事実は、
単層パーセプトロンの限界を端的に示している。
単層パーセプトロンに制限しなければ、
出力層と隠れ層の2層で構成される多層パーセプトロンでXOR演算を実行できることが知られており
（コラム参照）、
多層パーセプトロンはチューリングマシンなどと同等の計算能力を有しているとされる。

\begin{itembox}{\bf コラム　2層パーセプトロンによるXOR演算}
 　ああああ
\end{itembox}

  \begin{figure}
    \centering
    
    \caption{XORを計算するパーセプトロン}
    \label{fig:xor-perceptron}
  \end{figure}


単層パーセプトロンでは線形分離問題しか取り扱えないとしても、
線形分離問題を解決することには実用上の意義は存在する。
課題は、
原理的な線形分離問題であっても、
データに誤差や混入したり、外乱要因が存在することで、
実データは超平面で分離不可能な場合があることである。

例えば、
図~\ref{fig:with-errors}は、
図~\ref{fig:data-sample-1}と同じく$2x_1 - 4x_2 + 1 = 0$を分離直線とする
データの分布であるが、
データに誤差が含まれているためどのような直線を引いても、
ラベル1の点（■）とラベル0の点（●）を分離することができない。

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{fig/sample-2.pdf}
  \caption{誤差を含むデータの分布}
  \label{fig:with-errors}
\end{figure}

誤り訂正学習では、
このような訓練データから分離超平面を学習することが出来ないが、
これは「パーセプトロンがデータセットと無矛盾であるか、否か」という「デジタル」な指標に基づいて
学習を行っていることが理由である。
逆に言えば、
「パーセプトロンがデータをどの程度うまく分類しているか」という「アナログ」な指標を導入し、
この指標に基づいて学習を実行する必要がある。
次節では、
\textbf{損失関数}という概念を導入し、アナログな学習を実現する方法を見る。

\subsection{損失関数による限界突破}
\label{sec:loss-function}

図~\ref{fig:with-errors}では、
どのように直線をひいても、
ラベル0の毎に完全にデータを分離することは出来ない。
どのように重み$w_1, w_2$とバイアス$b$の値を調節しても、
必ず、ラベルとパーセプトロンの出力の間に「乖離」が発生する。
図~\ref{fig:with-errors}では、
$w_1 = 2, w_2 = -4, b = 1$を選択すると破線の直線が得られるが、
ラベルとパーセプトロンの出力の間の乖離は、
破線の直線の上側に1点だけ存在するラベル1の点（■）においてのみ発生する。
つまり、
訓練データに対して無矛盾なパーセプトロンは存在せず、
誤り訂正学習では問題を解決することができない。

\subsubsection{損失関数と残差二乗和}
\label{sec:loss-function-intro}

損失関数は「乖離の計量」であり、
\textbf{損失関数を最小にするように重みとバイアスを最適化}することで、
ラベルとパーセプトロンの出力の間の乖離を最小化するパラメータを選択する。

乖離は「誤差」と同義であることが多く、
誤差を計量する方法としては、
物理や統計において昔から広く使われてきた方法が存在する。
\textbf{二乗誤差和}や\textbf{残差平方和}と呼ばれる損失関数を最小化する
\textbf{最小二乗法}である。
以下では、線形回帰を例にとって、最小二乗法について説明する。


\paragraph{線形回帰.}
バネの伸びがバネにかかる張力に比例することはフックの法則として知られている。
バネ係数は張力に対する伸びの比例係数として与えられるが、
バネの伸びを計測した下記の実験データからバネ係数を求めることを考えよう。

\begin{center}
\begin{tabular}{c|rrrrrrrrrr}
  \toprule
  張力 (g) & 0 & 1 & 2 & 3 & 4 \\
  \midrule
  バネの長さ (cm) & 9.89 & 10.2 & 10.45 & 10.66 & 10.76 \\
  \bottomrule
\end{tabular}
\end{center}

図~\ref{fig:hook}では、$x$軸を張力、$y$軸をバネの長さとして、
上記のデータをプロットした。
プロットしたデータはトレンドとして直線のまわりにばらついていることが分かる。
バネ係数を求めるためには、
データに最もフィットする直線（\textbf{回帰直線}）を決定する必要がある。
ここでは、
フィットの程度の定量化として二乗誤差を利用し、
二乗誤差を最小にするようにパラメータ（この例では、直線の傾きと$y$切片）を決定する手法を示す。
この手法は、\textbf{最小二乗法}と呼はれ、自然科学・社会科学を問わず、
広い領域で利用されている。

\begin{figure}
  \centering
  \includegraphics[width=0.7\linewidth]{fig/hook.pdf}
  \caption{フックの法則}
  \label{fig:hook}
\end{figure}

今、
回帰直線の傾きを表すパラメータを$a$、$y$切片を表すパラメータを$b$、
回帰直線の方程式を$y = ax + b$と表す時、
この式から得られる理論値と実験データとの間の二乗誤差は次の式で与えられる。
$x$が張力を表し、張力が$x$の時のバネの長さの理論値が$ax + b$で計算される。

\[
  S(a, b) = (9.89 - b)^2
  + (10.2  - a - b)^2
  + (10.45 - 2a - b)^2
  + (10.66 - 3a - b)^2
  + (10.76 - 4a - b)^2
\]

二乗誤差は$a$と$b$の関数であることに注意しよう。
二乗誤差$S(a, b)$を最小化する$a$と$b$を求めることにより、
回帰直線を求める。
まず、$S(a, b)$を$a$と$b$に関して整理すると、
\[
  S(a, b) = 30.0 a^{2} + 20.0 a b - 212.24 a + 5.0 b^{2} - 103.92 b + 540.4678
\]
を得るが、右辺を$a$と$b$で偏微分して、その値を0とおく。
\begin{align*}
  &
    \frac{\partial S}{\partial a} = 60.0 a + 20.0 b - 212.24 = 0
  \\&
    \frac{\partial S}{\partial b} = 20.0 a + 10.0 b - 103.92 = 0
\end{align*}
この式を$a$と$b$に関する連立一次方程式と考えて、
$a$と$b$について解くことによって、最適解を得ることができる。
\[
  a = 0.22, \quad b = 9.952
\]

実は、図~\ref{fig:hook}のデータは、
$x = 0, 1, 2, 3, 4$に対して$y = 0.2x + 10$の値を計算し、
計算で得られた値に平均0・標準偏差0.05の正規分布に従う誤差を加算して生成したものである
（コラム「分散と残渣平方和」を参照）。
データから最小二乗法で推定したパラメータは、
$a = 0.2$と$b = 10$にかなり近いことが分かるであろう。

\newpage
\begin{itembox}{\bf 分散と残差平方和.}
  $n$個のデータ$x_1, \dots, x_n$が与えられた時、
  これらのデータの平均$\mu$が
  \begin{equation}\label{eq:7}
    \mu = \frac 1n\sum_{i=1}^n x_i
  \end{equation}
  で与えられることは周知であろう。
  本来、これらのデータは値$\mu$をとるべきであったが、
  誤差の混入により$\mu$の周りに「ばらついて」いるという状況を考えよう。
  このような状況は色々な場合に現れるもので、
  例えば、19世紀の科学者達は、望遠鏡を使って天体の位置の観測を行うと、
  計測する度に観測した位置がばらつくことに気がついていた。
  このようなデータのばらつきを定量化する方法として、
  \textbf{分散}という統計量が与えられている。
  分散$\sigma^2$は次の式で定義される。
  \[
    \sigma^2 = \frac 1n\sum_{i=1}^n (x_i - \mu)^2
  \]
  上式から、分散の正体は、$x_1, \dots, x_n$の「真の値」を$\mu$だと考えた時の、
  残差平方和$S$をデータの個数$n$で割った値$\frac Sn$であることに気づくであろう。
  実は、式~(\ref{eq:7})で与えられる平均の式は、残差平方和を最小にする$\mu$ｂの値、
  つまり、最小二乗法によってデータから求められた「真の値」である。
  実際、$\mu$を変数と考えて、残差平方和$S$を$\mu$で微分して導関数を計算して、
  その値を0と置くと、次の方程式を得る。
  \[
    \frac{dS}{d\mu} =
    -2 \sum_{i-1}^n (x_i - \mu) = 
    -2 \left( n\mu - \sum_{i-1}^n x_i\right) = 0
  \]
  この方程式を$\mu$に関して解けば、式~(\ref{eq:7})が得られる。
  即ち、
  我々が当たり前だと考えている、式~(\ref{eq:7})による平均の定義は、
  実は、最小二乗法から導かれる「定理」なのである。

  よく考えれば、
  式~(\ref{eq:7})を平均の自然な定義と考えている理由は、
  小学生の時の「刷り込み」に基づく思い込みに過ぎない。
  実際、古代ギリシアの数学者達は、
  平均の多義性に気がついており、
  式~(\ref{eq:7})で定義される算術平均に加え、
  幾何平均と調和平均の存在を記録に残している。

  最小二乗法の発見者は、史上最も偉大な数学者のひとりと言われるガウス
  （Johann Carl Friedrich Gauss、1777〜1855）である。
  ガウスは、天体観測を行う過程で、観測値に含まれる誤差の分布として、正規分布を発見しており、
  最小二乗法を駆使して天文学の研究を行っていたことが知られている。  
\end{itembox}

\newpage
\begin{itembox}{\bf コラム　微分.}
  関数$f(x)$が$x = a$で微分可能であるとは、
  $\Delta f = f(a + \Delta x) - f(a)$に対して、極限
  \[
    f'(a) = \lim_{\Delta x\to 0}\frac{\Delta f}{\Delta x}
    = \lim_{\Delta x\to 0}\frac{f(a + \Delta x) - f(a)}{\Delta x}
  \]
  が存在することをいう。
  関数$f(x)$が、任意の$x = a$で微分可能である時、
  \textbf{$f(x)$は微分可能である}といい、
  関数$f'(x)$を$f(x)$の\textbf{導関数}と呼ぶ。

  $f'(x)$を$\displaystyle \frac{df(x)}{dx}$と書くことも多い。
  記法の発明者の名前をとって、
  前者はラグランジュ（Lagrange, 1736-1813）の記法と呼ばれ、
  後者はライプニッツ（Leibniz, 1646-1716）の記法と呼ばれる。

  微分積分学は、ほぼ同時期に、ニュートン（Newton, 1642-1727）とライプニッツによって
  独立にその基礎が築かれた。
  成果の出版はライプニッツが先であるが、成果の発見はニュートンが先であり、
  そのため、「ライプニッツがニュートンの研究を盗用した」という主張もあったが、
  現在は独立の業績であると認められている。
\end{itembox}

\begin{itembox}{\bf コラム　微分の幾何的意味}
$\displaystyle f'(a)$は、
$y = f(x)$のグラフの点$(a, f(a))$での\textbf{接線の傾き}となる。
実際、下図のように、
\[
  \frac{\Delta f}{\Delta x} = \frac{f(a+\Delta x) - f(z)}{\Delta x}
\]
は点$(a, f(a))$と点$(a+\Delta x, f(a+\Delta x)$を結ぶ直線の傾きであり、
\[
  f'(a) = \lim_{\Delta x\to 0}\frac{\Delta f}{\Delta x}
\]
であるからである。

\vspace{10mm}
\begin{center}
\begin{tikzpicture}[domain=-1:5]
%  \draw[very thin,color=gray] (-1.1,-1.1) grid (4.9,4.9);
  \draw[->] (-0.2,0) -- (5.2,0) node[right] {$x$};
  \draw[->] (0,-1.2) -- (0,8.2) node[above] {$y$};
  \draw[ultra thick, red]   plot (\x, {- \x * \x / 5 + 2 * \x})
  node[right] {$y = f(x)$};
  \draw[dashed] (1,1.8) -- (1,0) node[below] {$a$};
  \draw[thin] (1,1.8) -- (5,7.4) (1,1.8) -- (5, 6.6) (1,1.8) -- (5,5.8);
  \draw[thick] plot(\x, {1.6 * \x + 0.2}) node[right] {接線};
  \draw[dashed] plot coordinates{(1,1.8) (2,1.8) (2,3.2)} -- cycle;
  \draw[dashed] plot coordinates{(1,1.8) (3,1.8) (3,4.2)} -- cycle;
  \draw[dashed] plot coordinates{(1,1.8) (4,1.8) (4,4.8)} -- cycle;
  \node at (4.4,3.3)  {$\Delta f$};
  \node at (2.5,1.4) {$\Delta x$};
  \draw[very thick, <-] (1.5,1.0) -- (3.5,1.0);
  \draw[very thick, <-] (5.2,7.5) -- (5.2,6);
  % \draw[color=red]    plot (\x,\x)             node[right] {$f(x) =x$};
  % % \x r means to convert ’\x’ from degrees to _r_adians:
  % \draw[color=blue]   plot (\x,{sin(\x r)})    node[right] {$f(x) = \sin x$};
  % \draw[color=orange] plot (\x,{0.05*exp(\x)}) node[right] {$f(x) = \frac{1}{20} \mathrm e^x$};
\end{tikzpicture}
\end{center}
\end{itembox}

二乗誤差と最小二乗法について理解したところで、
二乗誤差を利用したパーセプトロンの学習アルゴリズムについて述べる。

これまでと同じく$i$番目の訓練データを$\vc x[i] = (x_1[i], \dots, x_d[i])$、
ラベルを$t[i]$で表す。

訓練データ$\vc x[i]$を入力した時野パーセプトロンの出力は、
活性化関数を$f$として、
\[
  y[i] = f\left(b + \sum_{j=1}^d w_j x_i[i]\right)
\]
で計算される。
これまでは活性化関数をヘヴィサイド階段関数$f_0$に限定していたが、
実用で利用される活性化関数は複数種類存在するので、
以降ではヘヴィサイド階段関数に限定しない一般の関数$f$とする。
実際には、
ヘヴィサイド階段関数はこれから述べる学習アルゴリズム（勾配降下法）には適切ではないので、
別の関数で置き換えるが、それについては後述する。

訓練データ$\vc x[i]$に対する二乗誤差は$(t[i] - y[i])^2$で計算され、
損失関数は$i = 1, \dots, n$にわたる$(t[i] - y[i])^2$の総和で定義される。
即ち、損失関数$L$は
\[
  L(w_1, \dots, w_d, b)
  = \sum_{i=1}^n (t[i] - y[i])^2
  = \sum_{i=1}^n \left(t[i] - f\left(b + \sum_{i=1}^d w_i x_d[i]\right)\right)^2
\]
で定義される。
$t, x_1, \dots, x_d$は定数、$b, w_1, \dots, w_d$が変数である。
$L$を最小化する重み$w_1, \dots, w_d$とバイアス$b$を求めるために、
$L$を$w_i$と$b$で偏微分して、値を0と置くと、
$b, w_1, \dots, w_d$に関する連立方程式
\begin{align}
  &\label{eq:8}
    \frac{\partial L}{\partial w_i}
    = - \sum_{i=1}^n 
    2 \left(t[i] - f\left(b + \sum_{i=1}^d w_i x_d[i]\right)\right)
    f'\left(b + \sum_{i=1}^d w_i x_d[i]\right) x_d[i] = 0
  \\&\label{eq:9}
  \frac{\partial L}{\partial b}
  = - \sum_{i=1}^n 
  2 \left(t[i] - f\left(b + \sum_{i=1}^d w_i x_d\right)\right)
  f'\left(b + \sum_{i=1}^d w_i x_d[i]\right) = 0
\end{align}
を得る。
$f'$は$f$の微分（導関数）である。
線形回帰の例の場合と同様に、
損失関数を最小にする$w_1, \dots, w_d$と$b$を求めるために、
この連立方程式の解を求めたい。

この時、活性化関数がヘヴィサイド階段関数であると不都合があることが分かる。
ヘヴィサイド階段関数$f_0(x)$は、$x = 0$で微分可能ではなく、
$x \neq 0$では常に$f'(x) = 0$が成り立ってしまうからである。
実際、
ヘヴィサイド階段関数を使った場合の損失関数は、
離散的な値をとる階段関数になる。
この事実を単純な例を用いて確かめてみよう。

今、1個の入力$x_1$のみを許すパーセプトロンを考える。
パーセプトロンのパラメータは重み$w_1$とバイアス$b$であり、
\[
  y = f_0(w_1x_1 + b)
\]
が、このパーセプトロンの出力を定義する。
今、サンプルデータとして、図~\ref{fig:sample-one-dim}に示す6個の訓練データを考える。
ラベル1の訓練データは■、ラベル0の訓練データは●でプロットしている。

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{fig/sample-one-dim.pdf}
  \caption{1次元のサンプルデータ}
  \label{fig:sample-one-dim}
\end{figure}

この6個の訓練データに関して、損失関数を具体的に定義すると、
\begin{align*}
  L(w_1, b) =
  &
    \left(1 - f_0(4.5 w_1 + b)\right)^2 + \left(1 - f_0(16.0 w_1 + b)\right)^2 + \left(1 - f_0(9.8 w_1 + b)\right)^2
  \\&
  + \left(0 - f_0(0.4 w_1 + b)\right)^2 + \left(0 - f_0(7.2 w_1 + b)\right)^2 + \left(0 - f_0(5.7 w_1 + b)\right)^2
\end{align*}
となる。

一方、訓練データは1次元なので、その「超平面」は0次元、即ち、
「分離超平面」は点になる。
具体的には、$x_1 = -\frac b{w_1}$が「分離点」を定め、パーセプトロンの出力は、
\[
  y = f_0(w_1 x_1 + b) =
  \begin{cases}
    1, & \text{$x_1 > -\frac b{w_1}$の時}\\
    0, & \text{$x_1 < -\frac b{w_1}$の時}\\
  \end{cases}
\]
となる。

分離点は$w_1$と$b$の比で定まるので、
予め$w_1 = 1$とすることで分離点の座標$-b$をとし\footnote{
  $x_1 > -\frac b{w_1}　\Leftrightarrow y = 1$、即ち、
  $x_1 > -\frac b{w_1} \Leftrightarrow w_1x_1 + b > 0$が成り立つことが予見されるので、
  $w_1 > 0$を最初から仮定することが出来る。}、
$-b$の値を横軸にして損失関数$L(1, b)$をプロットすると図~\ref{fig:loss-step}を得る。
損失関数が階段関数であることが明瞭に理解できる。

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{fig/loss-step.pdf}
  \caption{ヘヴィサイド階段関数の場合の損失関数}
  \label{fig:loss-step}
\end{figure}

\subsubsection{ロジスティック関数}
\label{sec:logistic-function}

「損失関数が階段関数になってしまう」前述の問題は、
活性化関数として微分可能で、0でない傾きをもつ関数を選択すれば解決する。
その点で、
ロジスティック関数がヘヴィサイド階段関数の代替として広く使われている。
ロジスティック関数$\logi x$は、
\begin{itembox}{\bf ロジスティック関数}
\[
  \logi x = \frac 1{1 + e^{-x}}
\]
\end{itembox}
と定義され、
図~\ref{fig:logistic}で示すようなS字型のグラフをもつ。
\textbf{シグモイド関数}と呼ばれることも多いが、
「シグモイド」とは「S字型」という意味で、
広くはS字型のグラフを有する全ての関数を指す。
他のシグモイド関数と区別するために、標準シグモイド関数と呼ばれることもある。
実は、
ヘヴィサイド階段関数に替わる微分可能関数としてロジスティック関数が利用される理由は、
ロジスティック関数のグラフがヘヴィサイド階段関数のグラフのよい近似であること、
ロジスティック関数が計算の便宜上利点を有することの2点であり、
原理的な根拠が存在する訳ではない（コラムを参照）。

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{fig/logistic.pdf}
  \caption{ロジスティック関数}
  \label{fig:logistic}
\end{figure}

ロジスティック関数を活性化関数として利用すると、
図~\ref{fig:sample-one-dim}で示した例における損失関数は、
\begin{align}
  &\nonumber
    L(w_1, b)
  \\&\nonumber
    =
    \left(1 - \logi{4.5 w_1 + b}\right)^2 + \left(1 - \logi{16.0 w_1 + b}\right)^2 + \left(1 - \logi{9.8 w_1 + b}\right)^2
  \\&\label{eq:6}\quad
  + \left(0 - \logi{0.4 w_1 + b}\right)^2 + \left(0 - \logi{7.2 w_1 + b}\right)^2 + \left(0 - \logi{5.7 w_1 + b}\right)^2
\end{align}
となり、
活性化関数がヘヴィサイド階段関数の場合（図~\ref{fig:loss-step}）と同様に、
$w_1  = 1$として損失関数をグラフを描くと図~\ref{fig:loss-logistic}のようになる。
損失関数$L$は$b$の関数であるが、横軸は$-b$になることに注意して頂きたい。

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{fig/loss-logistic.pdf}
  \caption{ロジスティック関数の場合の損失関数（$w_1 = 1$）}
  \label{fig:loss-logistic}
\end{figure}

損失関数のグラフは連続な曲線となり、
$b = -8.3$の近傍で最小値を取り、
式~(\ref{eq:6})で定義される損失関数の観点からは、
「分離点」として$x = -8.3$（▼）を選ぶことが適切であることが分かる。

\newpage
\begin{itembox}{\bf コラム　ロジスティック関数}
ロジスティック関数は、人口の増加を表現する数理モデルとして、
1838年に数学者フェルフルスト（Pierre-François Verhulst、1804〜1849）によって導入された。
経済学者マルサス（Thomas Robert Malthus、1766〜1834）は、
社会的な産児制限の必要を訴え、当時の救貧法に反対する立場から、
その理論的な裏付けとして、
1798年に有名な「人口論」を発表している。
人口論においては、社会的制約がない状態では人口は指数関数に従って爆発的に増加し、
やがては、線形関数に従ってしか増加しない食料供給量を上まわり、飢餓を引き起こすとされる。
人口を指数関数でモデル化する人口論の手法は、
環境や資源が人口増加の抑制因子として働くことを無視している点で不自然であり、
フェルフルストはより自然な人口変化の数理モデルとしてロジスティック関数を導入した。
人口を$N$とし、人口の経時変化率$\frac{dN}{dt}$は、
人口を増加させるさせる因子$aN$と、
人口増加を抑制する因子$1 - \frac bN$の積で決定されるとすると、
微分方程式
\[
  \frac{dN}{dt} = aN\left(1 - \frac Nb\right)
\]
が導かれ、$N = b \logi{at}$はこの微分方程式の解である。
猩猩蠅などを使った実験によって、
生物の個体数の変化がロジスティック関数に従うことが確認されている。

また、ロジスティック関数を正規分布の累積確率関数の近似として利用することが提案され、
広く利用されている。
提案当初、「グラフの形状が似ている」以上の根拠がないことから、
その利用の是非を巡って激しい議論を呼び起こしたが、
計算の便宜上の利点が大きく、その実用的効用が認められている。
以下に、ロジスティック関数に関する重要な性質のいくつかを述べる。
\begin{itemize}
\item \textbf{増加関数である}。
  $e^{-x}$が減少関数であることに従う。
\item $\displaystyle \boldsymbol{\lim_{x \to \infty} \logi x = 1}$。
  $\displaystyle \lim_{x \to \infty} e^{-x} = 0$に従う。
\item $\displaystyle \boldsymbol{\lim_{x \to - \infty} \logi x = 0}$。
  $\displaystyle \lim_{x \to - \infty} e^{-x} = \infty$に従う。
\item $\boldsymbol{\logi{-x} = 1 - \logi x}$。
  $ 1 - \frac 1{1 + e^{-x}} =
    \frac {e^{-x}}{1 + e^{-x}} = \frac 1{e^x + 1}$に従う。
  \item $\boldsymbol{\logid x = \logi x \cdot \logi{-x}}$。
    合成関数の微分公式から導かれる。
    \[
    \left(\frac 1{1 + e^{-x}}\right)'
    = \frac{-1}{(1 + e^{-x})^2}\left(-e^{-x}\right)
    = \frac 1{1 + e^{-x}}\cdot\frac{e^{-x}}{1 + e^{-x}}
    \]
\end{itemize}
\end{itembox}

\newpage
引き続き、図~\ref{fig:sample-one-dim}に示す訓練データを使って、
どのように損失関数を最小にするパラメータを見つければよいかを見てみよう。
「分離点」$x_1 = - \frac b{w_1}$を求めることが目的であるので、
$w_1 = 1$と固定し、$L$を$b$のみの関数と考える。

\begin{align*}
  L(b)
  &
  = \left(1 - \logi{4.5 + b}\right)^2 + \left(1 - \logi{16.0 + b}\right)^2 + \left(1 - \logi{9.8 w + b}\right)^2
  \\&\quad
  + \left(0 - \logi{0.4 + b}\right)^2 + \left(0 - \logi{7.2 + b}\right)^2 + \left(0 - \logi{5.7 + b}\right)^2
\end{align*}

$L(b)$を最小化する$b$では損失関数$L(b)$の傾きが0となるので、
線形回帰の場合と同様に、
方程式$\frac{dL(b)}{db} = 0$の解として、
損失関数を最小化する「分離点」の座標$-b$を求めることが出来る。
そこで、
ロジスティック関数の性質である$\frac{d\logi x}{dx} = \logi x\logi{-x}$を利用して
損失関数$L(b)$の$b$に関する導関数を計算し、
方程式
\begin{align*}
  \frac{dL(b)}{db}
  &
    =
    - 2(1 - \logi{4.5 + b})\logi{4.5 + b}\logi{-4.5 - b}
  \\&\quad
  - 2(1 - \logi{16.0 + b})\logi{16.0 + b}\logi{-16.0 - b}
  \\&\quad
    - 2(1 - \logi{9.8 + b})\logi{9.8 + b}\logi{-9.8 - b}
  \\&\quad
    - 2(0 - \logi{0.46 + b})\logi{0.46 + b}\logi{-0.46 - b}
  \\&\quad
    - 2(0 - \logi{7.2 + b})\logi{7.2 + b}\logi{-7.2 - b}
  \\&\quad
  - 2(0 - \logi{5.7 + b})\logi{5.7 + b}\logi{-5.7 - b}
  \\&
  = 0
\end{align*}
を考える。
この方程式の解として最適な$b$を求めることができる道理であるが、
連立一次方程式で解を求めることが可能であった線形回帰のケースとは対照的に、
直接的にこの非線形方程式の解を求めることは困難であることが分かる。

\subsubsection{勾配降下法}
\label{sec:gradient-descent}

「損失関数の最小値を定める方程式を直接できない」という問題は人工ニューラルネットを実現する上で一般に発生し、
問題の解決は必須である。
そこで、
直接的にな方程式の解を求める代わりに、
\textbf{勾配降下法}と呼ばれる逐次計算によって解析的に解を求める手法が用いられる。
勾配降下法を用いれば、
活性化関数が各点で微分可能であれば、
かつ、関数を最小化する点でのみ導関数の値が0となるという条件を有していれば、
関数の定義によらず、損失関数を最小化する点を近似的に求めることができる。

図~\ref{fig:loss-logistic}で与えられた訓練データを例に用いながら、
勾配降下法の基本的な原理を見ていく。
説明の便宜のために、$w_1 = 1$を仮定するので、
分離点の座標は$x_1 = -b$で与えられる。

勾配降下法による学習も、誤り訂正学習と同じように、
「終了条件を満足するまで、予め定められた更新式により重みの更新を繰り返す」
というフレームワークに従う。

損失関数が$b$のみの関数であるこの例では、学習率$\eta > 0$に対して、更新式を
\begin{equation}\label{eq:10}
  b \leftarrow b - \eta \frac{dL}{db}(b)
\end{equation}
で与え、
更新の都度、$b$の値を$-\eta \frac{dL}{db}(b)$だけ変化させる。
式~(\ref{eq:10})は$b$の増減の方向と変化量を決定する。
\begin{itemize}
\item $\frac{dL}{db}(b) > 0$であれば、
  現在の$b$の値の周辺では$L(b)$は増加関数であるので、
  $L(b)$の値を減らすために$b$の値を「適度に」減らすべきである。
  実際、更新式における$b$の変分$-\eta\frac{dL}{db}(b)$は負であり、
  $b$の値は減少するように更新される。
  また、学習率$\eta$は$b$の変化量を調節するパラメータであることが分かる。
\item
  逆に、$\frac{dL}{db}(b) < 0$であれば、
  現在の$b$の値の周辺では$L(b)$は減少関数であるので、
  $L(b)$の値を減らすために$b$の値を適度に増やすべきである。
  実際、更新式における$b$の変分$-\eta\frac{dL}{db}(b)$は正となり、
  $b$の値は増加するように更新される。
\item $L(b)$の最小値を与える$b$の値を$b_0$と表す。
  $b$が$b_0$の近くに位置する時は$b$の変化を小さく抑える必要があり、
  逆に、
  $b$が$b_0$から離れている時には$b$を大きく変化させた方が早く$b_0$に到達することができる。
  一方、
  $b$が$b_0$に近ければ$\frac{dL}{db}(b)$の値は0に近く、
  $\left\vert\frac{dL}{db}(b)\right\vert$の値が大きければ$b$も$b_0$から離れている。
  式~(\ref{eq:10})では、
  $b$の変分を$\frac{dL}{db}(b)$に比例するように$-\eta\frac{dL}{db}(b)$と定めることにより、
  $b$が$b_0$に近づけば$b$の値の変化量が小さくなり、逆に、遠ければ（傾向として）変化量が大きくなる工夫を行っている。
\end{itemize}

以下では、$\eta = 10$とし、図~\ref{fig:loss-logistic}の例を用いて、
実際の計算を通して勾配降下法の手順の説明を行う。
表~\ref{tab:gd-dim-one}に、更新の各ステップにおいて計算される
分離点の座標$x_1 = -b$、
損失関数の導関数$\frac{dL}{dx_1} = -\frac{dL}{db}$、
損失関数$L$の値を整理する。

\begin{enumerate}\renewcommand\labelenumi{\textbf{ステップ\arabic{enumi}. }}
\item
  $b$の初期値を$b = 0$とすると、損失関数の値は$L(0) \approx 2.368$である
  （図~\ref{fig:rss-1dim}~(a)）。
\item  
  $b = 0$の時、$\frac{dL}{db}(0) \approx 0.299$と計算されるので、
  更新式により、
  \[
    b = 0 - \eta \times \frac{dL}{db}(0) \approx - 2.987
  \]
  と計算される。
  分離点の座標は$x_1 = -b \approx 2.987$となり、初期の位置から正の方向に移動する
  （図~\ref{fig:rss-1dim}~(b)）。  
\item
  $b \approx -2.987$の時、$\frac{dL}{db}(-2.987) \approx 0.094$と計算されるので、
  更新式により、
  \[
    b \approx -2.987 - \eta \times \frac{dL}{db}(-2.098) \approx - 3.932
  \]
  と計算される。
  分離点の座標は$x_1 = -b \approx 3.932$となり、前回の位置から更に正の方向に移動する
  （図~\ref{fig:rss-1dim}~(c)）。  
\item
  $b \approx -3.932$の時、$\frac{dL}{db}(-3.932) \approx 0.116$と計算されるので、
  更新式により、
  \[
    b \approx -3.932 - \eta \times \frac{dL}{db}(-3.932) \approx - 5.088
  \]
  と計算される。
  分離点の座標は$x_1 = -b \approx 5.088$となり、前回の位置から更に正の方向に移動する
  （図~\ref{fig:rss-1dim}~(d)）。  
\item
  $b \approx -5.088$の時、$\frac{dL}{db}(-5.088) \approx 0.172$と計算されるので、
  更新式により、
  \[
    b \approx -5.088 - \eta \times \frac{dL}{db}(-5.088) \approx - 6.811
  \]
  と計算される。
  分離点の座標は$x_1 = -b \approx 6.811$となり、前回の位置から更に正の方向に移動する
  （図~\ref{fig:rss-1dim}~(e)）。  
\item
  $b \approx -6.811$の時、$\frac{dL}{db}(-6.811) \approx 0.226$と計算されるので、
  更新式により、
  \[
    b \approx -6.811 - \eta \times \frac{dL}{db}(-6.811) \approx - 9.067
  \]
  と計算される。
  分離点の座標は$x_1 = -b \approx 9.067$となり、前回の位置から更に正の方向に移動する
  （図~\ref{fig:rss-1dim}~(f)）。  
\item
  $b \approx -9.067$の時、$\frac{dL}{db}(-9.067) \approx -0.129$と、
  初めて、負の値となる。
  導関数$\frac{dL}{db}$の値の符号が変わったことにより、
  \[
    b \approx -9.067 - \eta \times \frac{dL}{db}(-9.067) \approx - 7.775
  \]
  と計算される$b$の値は、初めて、増加する。
  分離点の座標は$x_1 = -b \approx 7.775$となり、今度は前回の位置から負の方向に移動する
  （図~\ref{fig:rss-1dim}~(g)）。  
\item
  6回目より後の更新では、
  $b$の値は増加と減少を交互に繰り返すが、
  増加・減少の幅は徐々に小さくなっていく。
  これは、分離点が損失関数を最小化する点に近づいてきて、
  損失関数のグラフの傾きの値が0に近くなる、
  即ち、更新の幅を決定する導関数$\frac{dL}{db}$の値が0に近くなることによる。
  更新式を14回適用した後の$b$の値は$b = - 8.290$であり、
  導関数の値は  $\frac{dL}{db}(- 8.290) \approx -0.008$と0に近い。
  図~\ref{fig:rss-1dim}~(h)を見ても、
  分離点は$x_1 = -b$のグラフである曲線の最低点に近くなっていることが分かる。
\end{enumerate}

14回以降、$b$の更新を継続すると、更新による$b$の値の変化は0に漸近していくが、
0になることはない。
従って、
$b$の値が「十分に収束」したと考えられる時点で、
それ以上の更新を中止し、
その時の$b$の値を損失関数を最小化する$b$の値の近似値として利用する。

\begin{figure}
  \centering
  \begin{minipage}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{fig/rss-1dim-0.pdf}

    (a) 初期値
  \end{minipage}
  \begin{minipage}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{fig/rss-1dim-1.pdf}

    (b) 1回更新後
  \end{minipage}

  \begin{minipage}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{fig/rss-1dim-2.pdf}

    (c) 2回更新後
  \end{minipage}
  \begin{minipage}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{fig/rss-1dim-3.pdf}

    (d) 3回更新後
  \end{minipage}

  \begin{minipage}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{fig/rss-1dim-4.pdf}

    (e) 4回更新後
  \end{minipage}
  \begin{minipage}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{fig/rss-1dim-5.pdf}

    (f) 5回更新後
  \end{minipage}

  \begin{minipage}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{fig/rss-1dim-6.pdf}

    (g) 6回更新後
  \end{minipage}
  \begin{minipage}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{fig/rss-1dim-14.pdf}

    (h) 14回更新後
  \end{minipage}

  \caption{勾配降下法による学習のシミュレーション}
  \label{fig:rss-1dim}
\end{figure}


\begin{table}
  \centering
  \caption{勾配降下法による学習}
  \label{tab:gd-dim-one}
  \begin{tabular}{rrrr}
    \toprule
    \bf 更新回数 & \bf $\boldsymbol{x_1 = -b}$ & \bf $\boldsymbol{\frac{dL}{dx_1} = - \frac{dL}{db}}$ & \bf $\boldsymbol{L}$\\
    \midrule
初期値 & 0.000 & -0.299 & 2.368 \\
1回 & 2.987 & -0.094 & 1.889 \\
2回 & 3.932 & -0.116 & 1.789 \\
3回 & 5.088 & -0.172 & 1.630 \\
4回 & 6.811 & -0.226 & 1.247 \\
5回 & 9.067 & 0.129 & 1.104 \\
6回 & 7.775 & -0.096 & 1.084 \\
7回 & 8.739 & 0.070 & 1.071 \\
8回 & 8.034 & -0.052 & 1.065 \\
9回 & 8.555 & 0.038 & 1.061 \\
10回 & 8.174 & -0.028 & 1.059 \\
11回 & 8.454 & 0.020 & 1.058 \\
12回 & 8.249 & -0.015 & 1.058 \\
13回 & 8.399 & 0.011 & 1.057 \\
14回 & 8.290 & -0.008 & 1.057 \\
\bottomrule                                 
  \end{tabular}
\end{table}

以上述べた例では、
説明を分かりやすくするために、$w_1 = 1$を仮定して損失関数$L$を$b$のみで定まる一変数関数としたが、
このような仮定は勿論便宜的なものである。
パーセプトロンが複数の入力$x_1, \dots, x_d$をとり、これら入力に対する重み$w_1, \dots, w_d$が複数存在する時には、
重みの一つを定数としただけでは損失関数$L$は一変数関数にはならず、
多くの重みを定数とすると分離超平面の探索範囲が著しく小さくなってしまう。
損失関数が多変数関数である場合に使うことができる勾配降下法が必要である。

\subsubsection{多次元関数における勾配降下法}
\label{sec:gradient-descent-multi-variate}


同じ図~\ref{fig:sample-one-dim}の例において、
今度は、損失関数を$w_1$と$b$の二変数関数であると考える。
損失関数を与える式~(\ref{eq:6})を再掲する。
\begin{align*}
  L(w_1, b) =
  &\nonumber
    \left(1 - \logi{4.5 w_1 + b}\right)^2 + \left(1 - \logi{16.0 w_1 + b}\right)^2 + \left(1 - \logi{9.8 w_1 + b}\right)^2
  \\&
  + \left(0 - \logi{0.4 w_1 + b}\right)^2 + \left(0 - \logi{7.2 w_1 + b}\right)^2 + \left(0 - \logi{5.7 w_1 + b}\right)^2
\end{align*}
損失関数$L(w_1, b)$がどのように分布するかを、$x$軸を$w_1$、$y$軸を$b$、$z$軸を$L(w_1, b)$として、
図~\ref{fig:rss-weight-bias}~(a)に示す。
図~\ref{fig:rss-weight-bias}~(b)は同じグラフを等高線図で表現したものである。

\begin{figure}
  \centering
    \includegraphics[width=0.7\linewidth]{fig/1-dim-3d.pdf}

    (a) 3次元空間内での表現
    \vspace{5mm}

    \includegraphics[width=0.7\linewidth]{fig/1-dim-contour.pdf}
    
    (b) 等高線による表現

  \caption{重み$w_1$とバイアス$b$に対する損失}
\label{fig:rss-weight-bias}
\end{figure}

図~\ref{fig:rss-weight-bias}を観察すると、
おおよそ$b = -8.3 w_1$の直線に沿って、
高い山脈と深い峡谷が連なることが読み取れる。
山脈と峡谷の境は$w_1 = 0$であり、
$w_1 < 0$では山脈が聳え、
$w_1 > 0$では峡谷が刻まれる。
この観察から、
損失関数を最小化するように重み$w_1$とバイアス$b$を選ぶのであれば、
$w_1 > 0$の領域で$b = -8.3w_1$を満たすように選ぶことが望ましいことを示している。
この観察は、
$w_1 = 1$を仮定した場合$b = -8.3$付近で損失関数が最小値をとる事実とも符合する。

実は、損失関数のこの性質は、以下の考察によって事前に予見することが出来る。

損失関数を最小値に近づける「よい」分離点の分布範囲は訓練データの分布によって
制限される。
例えば、図~\ref{fig:sample-one-dim}を観察すれば、
「よい」分離点は、
座標$x_1 = 7.2$のラベル0の点と、座標$x_1 = 9.8$のラベル1の点の中間、
座標でいえば、$8 < x_1 < 9$の区間あたりに存在するべき
ことが直感的に分かる。
つまり、
重み$w_1$とバイアス$b$が定める分離点の座標は$x_1 = -\frac b{w_1}$であるので、
$w_1$と$b$がよい分離点を定めるのであれば、
分離点の座標$-\frac b{w_1}$はこの範囲におさまり、
互いに概ね近い値をとると考えられる。
既に、
$w_1 = 1$の時には$b = -8.3$の近傍で損失関数が最小になることを観察しているので、
損失関数を最小値に近づける$w_1$と$b$の組み合わせでは、
$-\frac b{w_1}$の値が$8.3$に近いであろうこと、
即ち、$b = -8.3w_1$の直線の近傍に分布するであろうことが予見できる。

更に、$b = -8.3w_1$の直線上で、
$w_1<0$では損失関数の値が高く、
$w_1>0$では損失関数の値が小さくなることは以下のように説明できる。
図~\ref{fig:sample-one-dim}の訓練データの分布を見ると、
ラベル1のデータは座標が大きくなる側に分布し、逆に、
ラベル0のデータは座標が小さくなる側に分布しているので、
$w_1$と$b$を重みとバイアスにもつパーセプトロンの出力が、
$x_1 > - \frac b{w_1}$の範囲で1に近づくのであれば損失関数は小さくなり、逆に、
$x_1 > - \frac b{w_1}$の範囲で出力が0に近づくのであれば損失関数は大きくなる。
一方、
パーセプトロンの出力は$\logi{b + w_1x_1}$で定義され、
$b + w_1 x_1 > 0$を満たす入力に対して1に近くなり、逆に、
$b + w_1 x_1 ＜ 0$を満たす入力に対して1に近くなる。
つまり、
損失関数の値を小さくするためには、
$x_1 > -\frac b{w_1}$で$b + w_1x_1 > 0$が成立する必要があり、
そのための条件は$w_1 > 0$である。
逆に、$w_1 < 0$であれば、
$x_1 > -\frac b{w_1}$で$b + w_1x_1 < 0$が成り立ち、
損失関数の値は大きくなる。

$w_1 = 1$を仮定し損失関数を一変数関数として扱う場合では、
$b$の変分$\Delta b$を$-\eta\frac{dL}{db}(b)$で定めて、
$b$の値を更新した。
一方、損失関数を$w_1$と$b$に関する二変数関数と考える時には、
$w_1$の変分$\Delta w_1$と$b$の変分$\Delta b$の両方、即ち、
ベクトル$(\Delta w_1, \Delta b)$を決めなければならない。
この時、
できるだけ効率的に損失関数の最小値に辿り着くためには、
損失関数の変分
\[
  \Delta L = L(\bar w_1 + \Delta w_1, \bar b + \Delta b)
  - L(\bar w_1, \bar b)
\]
が最小になるように（負で絶対値が最大になるように）、
ベクトル$(\Delta w_1, \Delta b)$の方向を決める必要がある。
$\bar w_1, \bar b$を更新前の重みとバイアスであるとする。

$\Delta L$を厳密に評価することは難しいので、
$L(\bar w_1 + \Delta w_1, \bar b + \Delta b)$の近似値を求めることで、
$\Delta L$を近似的に評価する。
そのために、
図~\ref{fig:rss-weight-bias}~(a)に示す曲面$z = L(w_1, z)$上の
点$(\bar w_1, \bar b, L(w_1, \bar b))$において、
曲面の接平面$T$を考える。
$T$の方程式は、適当な係数$\omega, \beta$に対して、
\[
T: z = \omega (w_1 - \bar w_1) + \beta (b - \bar b) + L(\bar w_1, \bar b)
\]
と表されるが、
実は、係数$\omega, \beta$は偏微分で与えられ、接平面$T$の方程式は
\begin{equation}\label{eq:11}
  T: z = \frac{\partial L}{\partial w_1} (w_1 - \bar w_1)
  + \frac{\partial L}{\partial b} (b - \bar b) + L(\bar w_1, \bar b)
\end{equation}
と表される（コラム「偏微分」、「接超平面とテイラーを参照）。
この節では偏微分の計算を行うわけではないので、
\textbf{$\boldsymbol{\frac{\partial L}{\partial w_1}, \frac{\partial L}{\partial b}}$は
接平面の係数を表す単なる記号}だと思っておいて頂ければ十分である。

さて、
$w_1 = \bar w_1, b = \bar b$の近傍において、
接平面の方程式~(\ref{eq:11})の右辺は$L(w_1, b)$の近似を与える関数として利用することができる。
即ち、
$\Delta w_1 = w_1 - \bar w_1, \Delta b = b - \bar b$と置くと、
$\vert\Delta w_1\vert$と$\vert\Delta b\vert$が十分小さければ、近似式
\[
  L(w_1, b) \approx \frac{\partial L}{\partial w_1} \Delta w_1
  + \frac{\partial L}{\partial b} \Delta b + L(\bar w_1, \bar b)
\]
が成り立つので、損失関数の変分$\Delta L$を以下のように近似することが出来る。
\begin{screen}
\begin{equation}\label{eq:12}
  \Delta L \approx
  \frac{\partial L}{\partial w_1} \Delta w_1
  + \frac{\partial L}{\partial b} \Delta b
\end{equation}
\end{screen}

損失関数の変分$\Delta L$を最小化するようなベクトル$(\Delta w_1, \Delta b)$の方向を定めることが狙いであったので、
$\Delta L$の評価にこの近似式を利用することにしよう。

実は、
式~(\ref{eq:12})の右辺は、ベクトル$(\Delta w_1, \Delta b)$と
ベクトル$\left(\frac{\partial L}{\partial w_1}, \frac{\partial L}{\partial b}\right)$の内積である。
従って、
二つのベクトルのなす角を$\theta$と表すと、
\[
  \Delta L
  \approx 
  \left(\frac{\partial L}{\partial w_1}, \frac{\partial L}{\partial b}\right)
  \cdot (\Delta w_1, \Delta b)
  = \sqrt{\frac{\partial L}{\partial w_1}^2 + \frac{\partial L}{\partial b}^2} \cdot
  \sqrt{{\Delta w_1}^2 + {\Delta b}^2} \cdot \cos\theta
\]
が成り立つので、
$\Delta L$の値が取る範囲は
\[
  -\sqrt{\frac{\partial L}{\partial w_1}^2 + \frac{\partial L}{\partial b}^2} \cdot
  \sqrt{{\Delta w_1}^2 + {\Delta b}^2}
  \le \Delta L \le
  \sqrt{\frac{\partial L}{\partial w_1}^2 + \frac{\partial L}{\partial b}^2} \cdot
  \sqrt{{\Delta w_1}^2 + {\Delta b}^2}
\]
で与えられる（図~\ref{fig:inner-product}）。

\begin{figure}
  \centering
  
  \caption{ベクトルの内積}
  \label{fig:inner-product}
\end{figure}


特に、
$\Delta L =   -\sqrt{\frac{\partial L}{\partial w_1}^2 + \frac{\partial L}{\partial b}^2} \cdot
\sqrt{{\Delta w_1}^2 + {\Delta b}^2}$
が成り立つことと、
$\theta = \pi$（度表示では$\theta = 180^\circ$）が成り立つこと、
$(\Delta w_1, \Delta b)$が
$\left(-\frac{\partial L}{\partial w_1}, -\frac{\partial L}{\partial b}\right)$と同じ向きを持つことは、
全て同値である。

以上の考察により、以下の更新式が得られる。
\begin{screen}
\begin{equation}\label{eq:13}
  (w_1, b) \leftarrow
  (w_1, b) - \eta \cdot \left(\frac{\partial L}{\partial w_1},
    \frac{\partial L}{\partial b}\right)
\end{equation}
\end{screen}


関数の最小値を求めるこの方法（勾配降下法）は、斜面を転がるボールに喩えて理解することができる。
ボールは獲得する運動エネルギーを最大化する方向、
つまり、常に斜面の最も勾配が急な方向に降下し、
結果として、最短で斜面の最低部に到達する。
斜面の方程式を$z = f(x, y)$で表す時、
斜面上の点$(\bar x, \bar y, f(\bar x, \bar y))$における、
最急降下勾配の方向はベクトル
$\left(-\frac{\partial f}{\partial x}(\bar x, \bar y),
  -\frac{\partial f}{\partial y}(\bar x, \bar y)\right)$で与えられ、
更新式~(\ref{eq:13})における変分を定めるベクトルと一致する。
このことから、勾配降下法は\textbf{最急降下法}と呼ばれることもある。

勾配降下法の説明の最後に、式~(\ref{eq:6})で定義される損失関数$L(w_1, b)$について、
$\frac{\partial L}{\partial w_1}$と$\frac{\partial L}{\partial b}$を与える式を示す。
少し一般化して、
$n$個の訓練データ$x_1[1], \dots, x_1[n]$とラベル$t[1], \dots, t[n]$に対して定義される損失関数
\[
  L = \sum_{i=1}^n \left(t[i] - \varsigma(b + w_1 x_1[i])\right)^2
\]
に対する$\frac{\partial L}{\partial w_1}$と$\frac{\partial L}{\partial b}$は、
\begin{align}
  &\label{eq:18}
    \frac{\partial L}{\partial w_1} = -2 \sum_{i=1}^n
    \left(t[i] - \varsigma(b + w_1 x_1[i])\right)\varsigma(b + w_1 x_1[i])\varsigma(- b - w_1 x_1[i]) x_1[i]
  \\&\label{eq:19}
    \frac{\partial L}{\partial b} = -2 \sum_{i=1}^n
    \left(t[i] - \varsigma(b + w_1 x_1[i])\right)\varsigma(b + w_1 x_1[i])\varsigma(- b - w_1 x_1[i])
\end{align}
により計算することができる。
これらの式の導出は合成関数の微分公式によるが、
導出方法を知ることは必ずしも必要ではないので、
説明はコラム「合成関数の微分公式」に譲る。

\subsubsection{勾配降下法の計算例}
\label{sec:example-grad-descent}

図~\ref{fig:sample-one-dim}の訓練データセットを例に取り、
勾配降下法の計算例を示す。
式~(\ref{eq:6})で定義される損失関数に対して、
勾配ベクトルを計算するための偏微分の式は以下のように与えられる。

\begin{align}
  \frac{\partial L}{\partial w_1}(w_1, b) =
  &\nonumber
    -2 \left(1 - \varsigma(4.5 w_1 + b)\right)\varsigma(4.5 w_1 + b)\varsigma(- 4.5 w_1 - b)\cdot 4.5
  \\&\nonumber
  -2 \left(1 - \varsigma(16.0 w_1 + b)\right) \varsigma(16.0 w_1 + b)\varsigma(- 16.0 w_1 = b)\cdot 16.0
  \\&\nonumber
  -2 \left(1 - \varsigma(9.8 w_1 + b)\right)\varsigma(9.8 w_1 + b)\varsigma(- 9.8 w_1 - b\cdot 9.8
  \\&\nonumber
  -2 \left(0 - \varsigma(0.4 w_1 + b)\right)\varsigma(0.4 w_1 + b)\varsigma(- 0.4 w_1 - b)\cdot 0.4
  \\&\nonumber
  -2 \left(0 - \varsigma(7.2 w_1 + b)\right)\varsigma(7.2 w_1 + b)\varsigma(- 7.2 w_1 - b)\cdot 7.2
  \\&\label{eq:14}
  -2 \left(0 - \varsigma(5.7 w_1 + b)\right)\varsigma(5.7 w_1 + b)\varsigma(- 5.7 w_1 - b)\cdot 5.7
\end{align}

\begin{align}
  \frac{\partial L}{\partial b}(w_1, b) =
  &\nonumber
    -2 \left(1 - \varsigma(4.5 w_1 + b)\right)\varsigma(4.5 w_1 + b)\varsigma(- 4.5 w_1 - b)
  \\&\nonumber
  -2 \left(1 - \varsigma(16.0 w_1 + b)\right) \varsigma(16.0 w_1 + b)\varsigma(- 16.0 w_1 = b)
  \\&\nonumber
  -2 \left(1 - \varsigma(9.8 w_1 + b)\right)\varsigma(9.8 w_1 + b)\varsigma(- 9.8 w_1 - b
  \\&\nonumber
  -2 \left(0 - \varsigma(0.4 w_1 + b)\right)\varsigma(0.4 w_1 + b)\varsigma(- 0.4 w_1 - b)
  \\&\nonumber
  -2 \left(0 - \varsigma(7.2 w_1 + b)\right)\varsigma(7.2 w_1 + b)\varsigma(- 7.2 w_1 - b)
  \\&\label{eq:15}
  -2 \left(0 - \varsigma(5.7 w_1 + b)\right)\varsigma(5.7 w_1 + b)\varsigma(- 5.7 w_1 - b)
\end{align}

前述の実験と同様に、重みとバイアスの初期値を$w_1 = 1, b = 0$とし、
式~(\ref{eq:13})、(\ref{eq:14})、及び、(\ref{eq:15})を更新式として、
$w_1$と$b$の更新を実行してみる。
これまでの例と異なり、非常に多くの更新を実行するため、初回の更新式の適用を説明する。

初期状態は$w_1 = 1, b = 0$である。
式~(\ref{eq:14})と(\ref{eq:15})に$w_1 = 1, b = 0$を代入すると、
\begin{align*}
    \frac{\partial L}{\partial w_1}(1, 0) & \approx 0.1812
  \\
    \frac{\partial L}{\partial b}(1, 0) & \approx 0.2987
\end{align*}  
を得るので、
学習率$\eta = 0.01$のもとで、
結果を式~(\ref{eq:14})の右辺に値を代入すると
\begin{align*}
  (w_1, b) - \eta \cdot \left(\frac{\partial L}{\partial w_1},
  \frac{\partial L}{\partial b}\right)
  &
  \approx
    (1, 0) - 0.01 \cdot (0.1812, 0.2987)
  \\&
  = (0.9982, -0.0030)
\end{align*}
が、更新後の新しい$w_1$と$b$の値を定める。

損失関数$L(w_1, b)$を収束させるために、同様の更新を3,000回以上実行した。
表~\ref{tab:update}に、更新による
$w_1$、$b$、$\frac{\partial L}{\partial w_1}$、$\frac{\partial L}{\partial b}$、及び、$L(w_1, b)$
の変化を示すが、
全ての更新について記載することは不可能なので、250回毎の値を記す。
更新の回数が増えると、
勾配ベクトル$(\frac{\partial L}{\partial w_1}, \frac{\partial L}{\partial b})$の各成分が0に近づき、
それに伴い、$L(w_1, b)$の値の変分も0に近づいていく様子が分かる。

\begin{table}
  \centering
  \begin{tabular}{r|rr|rr|r}
    \toprule
    更新回数 & $w_1$ & $b$ & $\frac{\partial L}{\partial w_1}$ & $\frac{\partial L}{\partial b}$ & $L(w_1, b)$ \\
    \midrule
    0 & 1 & 0 & 0.1812 & 0.2987 & 2.3678 \\
    1 & 0.9982 & -0.0030 & 0.1818 & 0.2987 & 2.3665 \\
    250 & 0.1405 & -0.7371 & -0.0220 & 0.2157 & 1.1320 \\
    500 & 0.1845 & -1.1571 & -0.0140 & 0.1302 & 1.0593 \\
    750 & 0.2134 & -1.4231 & -0.0096 & 0.0868 & 1.0303 \\
    1000 & 0.2339 & -1.6068 & -0.0070 & 0.0621 & 1.0165 \\
    1250 & 0.2491 & -1.7415 & -0.0053 & 0.0467 & 1.0091 \\
    1500 & 0.2608 & -1.8445 & -0.0041 & 0.0363 & 1.0047 \\
    1750 & 0.2701 & -1.9255 & -0.0033 & 0.0289 & 1.0021 \\
    2000 & 0.2776 & -1.9907 & -0.0027 & 0.0235 & 1.0004 \\
    2250 & 0.2838 & -2.0440 & -0.0022 & 0.0193 & 0.9992 \\
    2500 & 0.2889 & -2.0881 & -0.0019 & 0.0161 & 0.9984 \\
    2750 & 0.2932 & -2.1251 & -0.0016 & 0.0135 & 0.9978 \\
    3000 & 0.2968 & -2.1563 & -0.0013 & 0.0115 & 0.9975 \\
    \bottomrule
  \end{tabular}
  \caption{更新式の適用（$\eta = 0.01$）}
  \label{tab:update}
\end{table}

図~\ref{fig:grad-descent-0.01}~(a)に、損失関数$L(w_1, b)$の値だけを取り出して、
更新回数を横軸として、値の変化をグラフとして表示する。
一般に、データセットのデータを全て用いた1回の更新作業を\textbf{エポック}と呼ぶので、
ここではエポック数と更新回数は同じ意味をもつ。
更新回数が500未満では、損失関数の値は急速に減少し、
更新回数が1,000回を超えると、
曲線の傾きは0に近づき、損失関数の値は1.0に近い値に収束していく。

一方、図~\ref{fig:grad-descent-0.01}~(b)に、
重み（横軸）とバイアス（縦軸）の変化を点$(w_1, b)$の軌跡として描画する。
初期値$(w_1, b) = (1, 0)$から出発し、最初は谷底に向かって急降下し、その後、
谷底に沿って進む様子が分かる。
図~\ref{fig:rss-weight-bias}より、
重み$w_1$とバイアス$b$を変化させた時、
損失関数は$b = -8.3 w_1\ (w_1 > 0)$の周辺で最小値を取ることが分かっているので、
勾配降下法による学習がうまく機能していることが分かる。

\begin{figure}
  \centering

  \includegraphics[width=0.8\linewidth]{fig/1-dim-lr-0.01.pdf}

  (a) 損失関数の推移（$\eta = 0.01$）

  \includegraphics[width=0.8\linewidth]{fig/1-dim-lr-0.01-contour.pdf}

  (b) $(w_1, b)$の軌跡（$\eta = 0.01$）

  \caption{勾配降下法による学習（$\eta = 0.01$）}
  \label{fig:grad-descent-0.01}
\end{figure}

誤り訂正学習ではパーセプトロンが訓練データセットと無矛盾になるまで重みとバイアスの更新を継続するが、
損失関数と勾配降下法では、
訓練データセットと無矛盾となる重みとバイアスが存在しない場合でも、
最適な重みとバイアスを探索する。
このため、
更新作業の終了条件を恣意的に決定する必要があり、
「損失関数の変分が十分に小さくなる」、「勾配が十分に小さくなる」、「十分な回数の更新を実行した」など条件を、
事前に定めた閾値に基づいて判定することが普通である。
この計算例では、更新回数が10,000回に到達するか、または、
\[
  \left(\frac{\partial L}{\partial w_1}\right)^2 +
    \left(\frac{\partial L}{\partial b}\right)^2 < 0.0001
\]
のいずれかが成立した時点で更新式の適用を停止するようにしている。

\subsubsection{学習率の選択}
\label{sec:selection-learning-rate}

正しい重みとバイアスの値を学習するためには、
学習率を適切に選択することが重要である。

図~\ref{fig:grad-descent-0.1}では、
学習率を$\eta = 0.1$に変更した時の損失関数の変化と重みとバイアスの軌跡を示す。
図~\ref{fig:grad-descent-0.1}~(a)に示すように、
$\eta = 0.1$の時には、
損失関数の値が激しく振動することが分かる。
この振動の原因は、
図~\ref{fig:grad-descent-0.1}~(b)の観察から理解することができる。

図~\ref{fig:grad-descent-0.1}~(b)を観察すると、
初期状態$(w_1, b) = (1, 0)$から出発した当初は、
谷底に向かって降下していき、
$\eta = 0.01$の時と同様の軌跡を描くことが分かる。
ところが、
谷の最低部に到達した後は、
$\eta = 0.01$の時のように谷底に沿うように進むのではなく、
谷底をまたぐような軌跡で振動しながら進んでいる。

この起動の違いは、
$\eta$の値が大きいことから、1回の更新あたりの重みとバイアスと変分が大きくなることによる。
つまり、谷の片側の斜面に点$(w_1, b)$が位置する時、
勾配ベクトルは谷底を向いているが、更新による変分が大きいため、
谷の最低部を通り越して、反対側の斜面に移動してしまう。
反対側の斜面では勾配ベクトルの向きが逆になり、
次の更新では、もといた斜面に移動する。
この経過の繰り返しが、損失関数の値の振動をうむのである。

\begin{figure}

  \includegraphics[width=0.8\linewidth]{fig/1-dim-lr-0.1.pdf}

  (a) 損失関数の推移（$\eta = 0.1$）
  
  \includegraphics[width=0.8\linewidth]{fig/1-dim-lr-0.1-contour.pdf}

  (b) $(w_1, b)$の軌跡（$\eta = 0.1$）
  
  \caption{勾配降下法による学習（$\eta = 0.1$）}
  \label{fig:grad-descent-0.1}
\end{figure}

表~\ref{tab:update-lr-0.1}で示した数値を観察しながら、実際に確認してみよう。
\begin{description}
\item[更新回数0回〜10回.]
  勾配ベクトル$(\frac{\partial L}{\partial w_1}, \frac{\partial L}{\partial b})$の成分は全て正であり、
  点$(w_1, b)$は初期位置から左下の方向、即ち、谷底に向かって降下していく。
  確かに、損失関数$L(w_1, b)$の値も漸減している。
\item[更新回数152回〜155回.]
  152回目の更新時、
  勾配ベクトル$(\frac{\partial L}{\partial w_1}, \frac{\partial L}{\partial b})$の成分は、
  それまでの正の値から負の値に変わり、点$(w_1, b)$の移動の向きが反転する。
  153回目の更新における移動で、
  $w_1$座標の値も0.1975から0.5973と大きく増大し、谷の左岸から右岸に一跳びで移動している。
  154回目と155回目の更新時には、
  点$(w_1, b)$は谷の右岸に位置しており、
  勾配ベクトル$(\frac{\partial L}{\partial w_1}, \frac{\partial L}{\partial b})$の成分は正であるので、
  移動の向きは反転して、谷の底にむけて左に移動する。
  しかし、
  155回目の更新時の移動量が大きいため、谷底を通り過ぎてしまい、
  156回目の更新時の点$(w_1, b)$は谷の左岸斜面に移動する。
\item[更新回数155回〜158回.]
  156回目の更新時の点$(w_1, b) = (0.5970, -2.1442)$は谷の左岸斜面に位置するため、
  勾配ベクトル$(\frac{\partial L}{\partial w_1}, \frac{\partial L}{\partial b})$の成分は再び正に変わり、
  点$(w_1, b)$の移動の向きは反転する。
  $w_1$座標の値は0.1994から0.5973と大きく増大し、点$(w_1, b)$は谷の左岸から右岸に一跳びで移動する。
  156回目と157回目の更新時には、
  点$(w_1, b)$は谷の右岸に位置するので、
  勾配ベクトル$(\frac{\partial L}{\partial w_1}, \frac{\partial L}{\partial b})$の成分は正となり、
  移動の向きは再び反転して、谷の底にむけて左に移動する。
  ただし、157回目の更新時には、移動量が大きいため、谷底をを通り過ぎてしまい、点$(w_1, b)$は谷の左側に移動する。
\item[更新回数158回以降.]
  158解明校の更新においても、これまでと同様に、谷の左岸と右岸の間の往来を繰り返す。
\end{description}

このように、点$(w_1, b)$は谷の左岸と右岸を往来し、それに起因して損失関数の値が振動するのである。
それでも、
点$(w_1, b)$が谷の左岸に位置する時は、谷の最低部に近いため、
損失関数の振動値の最低値は損失関数の最低値である1.0に近い。
更に、更新を続ければ、振動の幅も小さくなり、
やがては一定値（損失関数の最低値1.0付近）に収束する。

\begin{table}
  \centering
  \begin{tabular}{rrrrrr}
    \toprule
    更新回数 & $w_1$ & $b$ & $\frac{\partial L}{\partial w_1}$ & $\frac{\partial L}{\partial b}$ & $L(w_1, b)$ \\
    \midrule
    0 & 1 & 0 & 0.1812 & 0.2987 & 2.3678 \\
    1 & 0.9819 & -0.0299 & 0.1872 & 0.2979 & 2.3555 \\
    2 & 0.9632 & -0.0597 & 0.1943 & 0.2970 & 2.3431 \\
    3 & 0.9437 & -0.0894 & 0.2028 & 0.2961 & 2.3304 \\
    4 & 0.9234 & -0.1190 & 0.2130 & 0.2951 & 2.3174 \\
    5 & 0.9021 & -0.1485 & 0.2254 & 0.2942 & 2.3041 \\
    6 & 0.8796 & -0.1779 & 0.2407 & 0.2934 & 2.2902 \\
    7 & 0.8555 & -0.2072 & 0.2600 & 0.2930 & 2.2756 \\
    8 & 0.8295 & -0.2365 & 0.2846 & 0.2931 & 2.2599 \\
    9 & 0.8011 & -0.2658 & 0.3169 & 0.2940 & 2.2428 \\
    10 & 0.7694 & -0.2952 & 0.3605 & 0.2962 & 2.2234 \\
    $\vdots$ &&&&&\\
    150 & 0.6014 & -2.1074 & 1.9177 & 0.2913 & 1.5823 \\
    151 & 0.4096 & -2.1365 & 2.1212 & 0.2830 & 1.1430 \\
    152 & 0.1975 & -2.1648 & -3.9978 & -0.3842 & 1.1791 \\
    153 & 0.5973 & -2.1264 & 1.9528 & 0.2939 & 1.5688 \\
    154 & 0.4020 & -2.1558 & 2.0258 & 0.2679 & 1.1219 \\
    155 & 0.1994 & -2.1826 & -3.9766 & -0.3837 & 1.1783 \\
    156 & 0.5970 & -2.1442 & 1.9649 & 0.2941 & 1.5631 \\
    157 & 0.4006 & -2.1736 & 1.9854 & 0.2611 & 1.1143 \\
    158 & 0.2020 & -2.1997 & -3.9171 & -0.3799 & 1.1745 \\
    159 & 0.5937 & -2.1617 & 1.9938 & 0.2960 & 1.5514 \\
    \bottomrule
  \end{tabular}
  \caption{更新式の適用（$\eta = 0.1$）}
  \label{tab:update-lr-0.1}
\end{table}

このように、学習率を不適切に大きく取ると、
損失関数の値が振動し、
損失関数の値が収束するまでに時間がかかってしまう可能性がある。
一方、適正な学習率は問題毎に異なり、
事前に適正な値を選択することが困難な場合もある。
その様な場合、
損失関数の変動を観察して、試行錯誤により適正な値を探索する必要となる。

\subsection{勾配喪失問題}
\label{sec:grad-loss-problem}

前節で説明したように、
勾配降下法では、
損失関数が定める曲面上を勾配が最大となるに方向に逐次降下することにより、
損失関数が最小になる地点を探索する。

一方、
重みとバイアスの広い領域において勾配が0に近くなるという現象が起こることがある。
このような領域に位置する点$(w_1, b)$に更新式を適用すると、
勾配ベクトル$\left(\frac{\partial L}{\partial w_1}, \frac{\partial L}{\partial b}\right)$の成分がほぼ0になるので、
更新式における変分$(-\eta)\cdot\left(\frac{\partial L}{\partial w_1}, \frac{\partial L}{\partial b}\right)$の成分もほぼ0になり、
重み$w_1$の値もバイアス$b$の値もほとんど変化しなくなってしまう。
即ち、損失関数が最小値になる以前に、重みとバイアスの値が収束してしまうという問題が発生する。

この問題を\textbf{勾配喪失問題}や\textbf{勾配消失問題}などとよぶ。
図~\ref{fig:rss-weight-bias}に、図~\ref{fig:sample-one-dim}の訓練データが定める損失関数の曲面を示したが、
図~\ref{fig:grad-loss}では、この曲面において勾配が喪失する領域を示した。
全体の半分くらいの領域で勾配が喪失していることが分かる。
勾配降下法による探索中にこの領域にはまり込んでしまうと、
この領域から脱出出来なくなり、損失関数を最小化する領域（谷底）に到達できなくなる。

\begin{figure}
  \centering

  \includegraphics[width=0.7\linewidth]{fig/grad-loss-3d.pdf}

  (a) 3次元空間内での表現

  \includegraphics[width=0.7\linewidth]{fig/grad-loss-contour.pdf}

  (b) 等高線による表現

  \caption{勾配が喪失する領域}
  \label{fig:grad-loss}
\end{figure}

以下では、
学習率を更に大きく$\eta = 1$として更新式を適用した時に、
点$(w_1, b)$が谷を大きく飛び越してしまい、勾配が喪失している領域にトラップされてしまう現象を観察する。

初期条件は今までと同じく$w_1 = 1, b = 0$とする。
図~\ref{fig:grad-descent-1}~(a)は、
更新式の適用回数に対する損失関数の値の推移をグラフとして示しているが、
損失関数の値は2.0付近に収束していくことが分かる。
既に確認したように、損失関数の最小値は1.0付近であり、両者の乖離は大きい。
勾配降下法の実行中に、
点$(w_1, b)$が勾配が喪失している領域にはまり込んでしまったことが想定できる。

実際、
図~\ref{fig:grad-descent-1}~(b)で点$(w_1, b)$の軌跡を確認すると、
初期状態から、一旦、谷底に向けて急降下して、谷の左岸に移動した後、再び、右岸に移動するが、
この時の移動量が大きいため（$\eta = 1$であることによる）、
斜面を下って谷底の方向に移動している途中で、勾配が喪失している領域にはまり込んでトラップされる様子がよく分かる。
勾配が喪失している領域につかまった後は、
計算された点$(w_1, b)$の位置を示すマーカー（〇）の間隔が詰まっていることから、
更新1回あたりの変分が小さくなることが観察できる。
この事実は、
表~\ref{tab:update-lr-1}で
勾配ベクトル$\left(\frac{\partial L}{\partial w_1}, \frac{\partial L}{\partial b}\right)$
の成分の数値を確認することでも、確認することができる。
60回目以降の更新では極めて0に近い値となっている。

\begin{figure}

  \includegraphics[width=0.8\linewidth]{fig/1-dim-lr-1.pdf}

  (a) 損失関数の推移（$\eta = 1$）
  
  \includegraphics[width=0.8\linewidth]{fig/1-dim-lr-1-contour.pdf}

  (b) $(w_1, b)$の軌跡（$\eta = 1$）
  
  \caption{勾配降下法による学習（$\eta = 1$）}
  \label{fig:grad-descent-1}
\end{figure}

\begin{table}
  \centering
  \begin{tabular}{rrrrrr}
    \toprule
    更新回数 & $w_1$ & $b$ & $\frac{\partial L}{\partial w_1}$ & $\frac{\partial L}{\partial b}$ & $L(w_1, b)$ \\
    \midrule
    0 & 1 & 0 & 0.1812 & 0.2987 & 2.3678 \\
    1 & 0.8188 & -0.2987 & 0.3019 & 0.2890 & 2.2387 \\
    2 & 0.5169 & -0.5877 & 1.2925 & 0.3831 & 1.9463 \\
    3 & -0.7756 & -0.9708 & -0.0720 & 0.0468 & 3.0208 \\
    4 & -0.7036 & -1.0176 & -0.1065 & 0.0384 & 3.0125 \\
    $\vdots$ &&&&&\\
    60 & 3.7284 & -4.2207 & 0.0048 & 0.0105 & 2.0057 \\
    61 & 3.7235 & -4.2313 & 0.0047 & 0.0103 & 2.0056 \\
    62 & 3.7188 & -4.2415 & 0.0046 & 0.0101 & 2.0054 \\
    63 & 3.7142 & -4.2516 & 0.0045 & 0.0099 & 2.0053 \\
    64 & 3.7096 & -4.2615 & 0.0044 & 0.0096 & 2.0052 \\
    65 & 3.7052 & -4.2711 & 0.0043 & 0.0094 & 2.0051 \\
    66 & 3.7008 & -4.2806 & 0.0043 & 0.0093 & 2.0050 \\
    67 & 3.6966 & -4.2898 & 0.0042 & 0.0091 & 2.0049 \\
    \bottomrule
  \end{tabular}
  \caption{更新式の適用（$\eta = 1$）}
  \label{tab:update-lr-1}
\end{table}

勾配喪失問題は、宿命的に人工ニューラルネットにつきまとう問題であり、
様々な局面で様々な理由で現れ、研究者にその解決を要請する。
このケースで観察された勾配喪失問題の原因は、
損失関数である残差二乗和と活性化関数であるロジスティック関数の組み合わせにある。
次節以降では、
損失関数と活性化関数をそれぞれ変更することにより、
勾配喪失問題の解決を試みる。

\begin{itembox}{\bf 偏微分}
  
\end{itembox}

\begin{itembox}{\bf 接超平面とテイラー展開}
  
\end{itembox}

\begin{itembox}{\bf 合成関数の微分公式}
  
\end{itembox}

\subsection{勾配喪失問題の解決ー交差エントロピーによる損失関数}
\label{sec:activate-function}

活性化関数を一般に$f(u)$とする。
残差平方和を損失関数、$f'(u)$を$f(u)$の導関数（微分）とする時、
勾配の計算式において次が成り立つ。
\begin{align*}
  &
    \frac{\partial L}{\partial w_1}
    = -2\cdot \sum_{i=1}^n \left(t[i] - f(b + w_1 x_1[i])\right)\cdot f'(b + w_1 x_1[i]) x_1[i]
  \\&
    \frac{\partial L}{\partial b}
  = -2\cdot \sum_{i=1}^n \left(t[i] - f(b + w_1 x_1[i])\right)\cdot f'(b + w_1 x_1[i])
\end{align*}
$f(u)$がロジスティック関数$\varsigma(u)$である時、
\[
  \varsigma'(u) = \varsigma(u) \cdot \varsigma(-u)
\]
が成り立つが（コラム「ロジスティック関数」）、
この事実からも、
絶対値$\left\vert u\right\vert$が大きいと$\varsigma'(u)$の値が0に
近くなることが分かり、
勾配喪失問題の原因となる（図~\ref{fig:grad-loss-logistic-function}）。

\begin{figure}
  \centering
  
  \caption{ロジスティック関数における勾配喪失}
  \label{fig:grad-loss-logistic-function}
\end{figure}

そこで、残差平方和を別の損失関数で置き換えることを考える。
$y[i] = \varsigma(b + w_1 x_1[i])$と表す時、
残差平方和は
$\displaystyle \sum_{i=1}^n \left(t[i] - y[i]\right)^2$と表されるが、
その代替となる\textbf{交差エントロピー}は次式で定義される。
\[
  H(t \Vert y) = \sum_{i=1}^n \left( - t[i] \log y[i]
    - (1 - t[i])\log (1 - y[i])\right)
\]
関数$- t \log y - (1 - t) \log (1 - y)$は、
$t = 1$の時は減少関数$- \log y$となり、$y = 1$で値は0となる。
一方、$t = 0$の時は増加関数$- \log (1 - y)$となり、$y = 0$で値は1となる。
つまり、
$H(t, y)$は、$\vert t - y\vert$に関して、増加関数であり、
$H(t, y) = 0$と$t = y$とは同値である。

交差エントロピーの意味については後述することとして、
交差エントロピーを損失関数として利用することにより、
勾配喪失問題が解決できることを見る。

図~\ref{fig:sample-one-dim}に示される訓練データに対して、
交差エントロピーを用いた損失関数$L(w_1, b)$は以下のように与えられる。
\begin{align}
  L(w_1, b) =
  &\nonumber
    - \log\logi{4.5 w_1 + b}  - \log\logi{16.0 w_1 + b}
    - \log\logi{9.8 w_1 + b}
  \\&\nonumber
  - \log\left(1 - \logi{0.4 w_1 + b}\right)
  - \log\left(1 - \logi{7.2 w_1 + b}\right)
  \\&\label{eq:16}
  - \log\left(1 - \logi{5.7 w_1 + b}\right)
\end{align}

図~\ref{fig:x-entropy-weight-bias}~(a)は
損失関数$L(w_1, b)$のグラフを3次元で描画したものであり、
図~\ref{fig:x-entropy-weight-bias}~(b)は
同じグラフを等高線で表現したものである。
残差平方和を使った損失関数のグラフである図~\ref{fig:grad-loss}と比較して、
勾配が喪失した領域がなくなっていることが分かる。
どのような重み$w_1$とバイアス$b$の初期値から出発しても、
$b = - 8.3 w_1$に沿った損失関数を最小化する領域に収束するであろうことが、
直感的にも理解することができる。

\begin{figure}
  \centering
    \includegraphics[width=0.7\linewidth]{fig/1-dim-xe-3d.pdf}

    (a) 3次元空間内での表現
    \vspace{5mm}

    \includegraphics[width=0.7\linewidth]{fig/1-dim-xe-contour.pdf}
    
    (b) 等高線による表現

  \caption{交差エントロピーによる損失関数}
\label{fig:x-entropy-weight-bias}
\end{figure}

これは次の理由による。
残差平方和に基づく損失関数に対して勾配ベクトルの成分を計算すると、
\begin{align*}
  &
    \frac{\partial L}{\partial w_1}
    = -2\cdot \sum_{i=1}^n \left(t[i] -
    \logi{b + w_1 x_1[i]}\right)\cdot
    \logi{b + w_1 x_1[i]}\cdot \logi{- b - w_1 x_1[i]}x_1[i]
  \\&
  \frac{\partial L}{\partial b}
    = -2\cdot \sum_{i=1}^n \left(t[i] -
    \logi{b + w_1 x_1[i]}\right)\cdot
    \logi{b + w_1 x_1[i]}\cdot \logi{- b - w_1 x_1[i]}
\end{align*}
が得られ、
$\left\vert b + w_1 x_1[i]\right\vert$が大きい時に、
因子$\logi{b + w_1 x_1[i]}\cdot \logi{- b - w_1 x_1[i]}$の値が
ほぼ0になってしまうことが、
勾配喪失問題の原因であることは既に述べた。

一方、
交差エントロピーに基づく損失関数の勾配ベクトルを計算する式は、
\begin{align*}
    \frac{\partial L}{\partial w_1}
  &
    =  \sum_{i=1}^n \left(- \frac 1{\logi{b + w_1 x_1[i]}}
    + \frac 1{\logi{- b - w_1 x_1[i]}}\right)\cdot
    \logi{b + w_1 x_1[i]}\cdot \logi{- b - w_1 x_1[i]}x_1[i]
  \\&
    =  \sum_{i=1}^n \left(\logi{b + w_1 x_1[i]}
  - \logi{- b - w_1 x_1[i]}\right) x_1[i]
  \\
  \frac{\partial L}{\partial b}
  &
    =  \sum_{i=1}^n \left(- \frac 1{\logi{b + w_1 x_1[i]}}
    + \frac 1{\logi{- b - w_1 x_1[i]}}\right)\cdot
    \logi{b + w_1 x_1[i]}\cdot \logi{- b - w_1 x_1[i]}  
  \\&
    =  \sum_{i=1}^n \left(\logi{b + w_1 x_1[i]}
  - \logi{- b - w_1 x_1[i]}\right)
\end{align*}
で与えられ、
分子と分母で$\logi{b + w_1 x_1[i]}\cdot \logi{- b - w_1 x_1[i]}$が
キャンセルして消えるからである。
ロジスティック関数のグラフ（図~\ref{fig:logistic}）を思い出せば分かるように、
$\logi{b + w_1 x_1[i]} - \logi{- b - w_1 x_1[i]}$が0の近傍に値を取る
広い範囲の$(w_1, b)$で0に近くなることはない。

図~\ref{fig:x-entropy-vary}に、
学習率$\eta = 0.01$で重みとバイアスの初期値を変えて勾配降下法をシミュレーションした結果を示す。
重みとバイアスの初期値によらず同じ場所に収束する様子が観察できる。

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{fig/x-entropy-vary.pdf}
 
  \caption{初期値を変えた勾配降下法の適用（$\eta = 0.01$）}
  \label{fig:x-entropy-vary}
\end{figure}

勾配ベクトルの計算については、コラム「勾配ベクトルの計算」に詳しく説明する。

\begin{itembox}{\bf コラム 勾配ベクトルの計算}
  
\end{itembox}

交差エントロピーの意味について説明する。
交差エントロピーを理解するためには、
確率分布の間の「距離」を与える
\textbf{カルバック・ライブラー情報量}を理解する必要があるので、
まず、カルバック・ライブラー情報量をサイコロの例を用いて説明する。

サイコロが一つ与えられていて、
下表はそのサイコロを1,200回振って出た目を記録した結果である。

\begin{center}
  \begin{tabular}{r|rrrrrr}
    \toprule
\bf 出目 & \bf 1 & \bf 2 & \bf 3 & \bf 4 & \bf 5 & \bf 6 \\
    \midrule
\bf 出現回数 & 208 & 194 & 195 & 193 & 198 & 212 \\
    \bottomrule
  \end{tabular}
\end{center}

この実験により出目$i$が得られる確率$q_i$は
\begin{align*}
  &
    q_1 = \frac{53}{300}, \qquad
q_2 = \frac{63}{400}, \qquad
    q_3 = \frac{49}{300},
    \\&
q_4 = \frac{14}{75}, \qquad
q_5 = \frac{199}{1200}, \qquad
q_6 = \frac{3}{20}    
\end{align*}
と定められる。
この確率分布$q_1, \dots, q_6$が、出目に偏り無い理想のサイコロの出目の確率分布
\[
  p_1 = p_2 = p_3 = p_4 = p_5 = p_6 = \frac 16
\]
からどれくらい乖離しているかを、
カルバック・ライブラー情報量で定量化することができる。
この例におけるカルバックライブラー情報量は以下のように計算される
（カラム「カルバック・ライブラー情報量」）。
\begin{align*}
  D_{KL}(p \Vert q)
  & 
    = \sum_{i = 1}^6 - p_i \log \frac{q_i}{p_i}
  \\&
  = - \frac 16 \log \frac{37}{240} \cdot \frac 61
  - \frac 16 \log \frac{41}{240} \cdot \frac 61
  - \frac 16 \log \frac{37}{240} \cdot \frac 61
  \\&\quad
  - \frac 16 \log \frac{9}{50} \cdot \frac 61
  - \frac 16 \log \frac{69}{400} \cdot \frac 61
  - \frac 16 \log \frac{101}{600} \cdot \frac 61
  \\&
  = - \frac 16 \log \frac{37}{240}
  - \frac 16 \log \frac{41}{240}
  - \frac 16 \log \frac{37}{240}
  \\&\quad
  - \frac 16 \log \frac{9}{50}
  - \frac 16 \log \frac{69}{400}
  - \frac 16 \log \frac{101}{600}
  - \log 6
\end{align*}
偏りのないサイコロの確率分布を基準で固定と考えると、
常識の最後の項$- \log 6$は定数である。
サイコロを1,200振る実験を何セットも繰り返して、
$D_{KL}(p \Vert q)$を何回も評価する時には、
定数項を何回も評価する計算は冗長である。
そこで、カルバック・ライブラー情報量から定数項を除くことで、
差分エントロピーを定義する。

\begin{itembox}{\bf 交差エントロピー}
  事象$E_1, \dots, E_n$に対して二つの確率分布$p_1, \dots, p_n$と
  $q_1, \dots, q_n$が与えられた時、
  差分エントロピーは次式で定義される。
  \[
    H(p\Vert q) = \sum_{i=1}^n - p_i \log q_i
  \]
\end{itembox}
従って、
サイコロの例における差分エントロピーは、
\begin{align*}
  H(p\Vert q) = 
  &
  - \frac 16 \log \frac{37}{240}
  - \frac 16 \log \frac{41}{240}
  - \frac 16 \log \frac{37}{240}
  \\&
  - \frac 16 \log \frac{9}{50}
  - \frac 16 \log \frac{69}{400}
  - \frac 16 \log \frac{101}{600}
\end{align*}
と計算される。

さて、パーセプトロンの損失関数に交差エントロピーを適用する考え方を説明する。
パーセプトロンは入力のラベル$t$を予測する「分類器」であるが、
確定的な予測を行うのではなく、
$t = 1$である確率を出力すると考える。
つまり、
パーセプトロンの出力$\logi{w_1 x_1 + b}$は、
$t = 1$である確率$q_1$を意味すると解釈する。
ロジスティック関数は0と1の間の値をとることから、
パーセプトロンの出力を確率と解釈することが可能である。
この解釈では、
$t = 0$である確率は$q_0 = 1 - \logi{w_1 x_1 + b}$となる。

一方、
理想のパーセプトロンは、
$t = 1$が成り立つ時は、
$t = 1$である確率を$p_1 = 1$と出力し、
$t = 0$である確率を$p_0 = 0$と出力する。
逆に、
$t = 0$が成り立つ時は、
$t = 1$である確率を$p_1 = 0$と出力し、
$t = 0$である確率を$p_0 = 1$と出力する。
$t = 1$と$t = 0$の両方のケースをあわせると、
$p_1 = t, p_0 = 1 - t$が理想のパーセプトロンの出力の確率分布である。

交差エントロピーを損失関数として利用する時は、
現在の重み$w_1$とバイアス$b$をもつパーセプトロンの予測の確率分布$q_0, q_1$が、
理想の確率分布$p_0, p_1$からどれくらい乖離しているかを評価する。
つまり、
\begin{align*}
  H(p \Vert q)
  &
    = - p_1 \log q_1 - p_0 \log q_0
  \\&
  = - t \log \logi{w_1 x_1 + b} - (1 - t) \log \left(1 - \logi{w_1 x_1 + b}\right)
\end{align*}
によって、パーセプトロンがどの程度正確であるかを評価するのである。

複数の訓練データ$x_1[1], \dots, x_1[n]$とラベル$t[1], \dots, t[n]$が与えられた時には、
それぞれの訓練データとラベルのペアに対して交差エントロピーを計算し、
その和によって損失関数を定義する。
即ち、入力のリンクを1個しか持たないパーセプトロンでは、
その損失関数は次のように定義できる。

\begin{itembox}{\bf 交差エントロピーによる損失関数}
  訓練データ$x_1[1], \dots, x_1[n]$とラベル$t[1], \dots, t[n]$が与えられたとする。
  \begin{align}
    L(w_1, b) = \sum_{i=1}^n
    \big [
    &\nonumber
      - t[i] \log \logi{w_1 x_1[i] + b}
    \\&\label{eq:17}
      - (1 - t[i]) \log \left(1 - \logi{w_1 x_1[i] + b}\right)\big]
  \end{align}
\end{itembox}
実際、
図~\ref{fig:sample-one-dim}で与えられる訓練データに対して式~(\ref{eq:17})の定義を適用すると、
式~(\ref{eq:16})を得る。

\begin{itembox}{\bf コラム　カルバック・ライブラー情報量}
  
\end{itembox}

\begin{itembox}{\bf コラム　勾配ベクトルの計算}
  
\end{itembox}

ロジスティック関数を活性化関数、交差エントロピーを損失関数とするパーセプトロンは、
データ分析に広く利用されている\textbf{ロジスティック回帰}と本質的に同値である。
ロジスティック回帰については、コラム「ロジスティック回帰」で説明する。

\begin{itembox}{\bf コラム　ロジスティック回帰}
  
\end{itembox}

\subsection{勾配喪失問題の解決ーReLU関数による活性化関数}
\label{sec:relu}

\ref{sec:activate-function}節では、損失関数を変更することにより勾配喪失問題を解決したが、
この節では、損失関数は残差平方和とし、活性化関数を変更することにより問題を解決する。
ロジスティック関数$\logi u$を活性化関数とした時に勾配喪失問題が発生した理由は、
ロジスティック関数の導関数（微分）$\logid u$が広い$u$の範囲で0に近い値になることに由来した。
ここでは、
導関数$f'(u)$が0に近い値をもつ$u$の範囲が制限される関数を活性化関数として利用することにより、
勾配喪失問題を解決することを目指す。

まず、活性化関数を恒等写像$f(u) = u$としてみよう。
恒等写像では、
常に$f'(u) = 1$が成立するので、
勾配喪失問題は解決される筈である。
実際、
図~\ref{fig:sample-one-dim}で与えられる訓練データに対する損失関数$L(w_1, b)$は、
以下の式で与えられ、
そのグラフは図~\ref{fig:identity-weight-bias}に示すような形状となる。
\begin{align*}
  L(w_1, b) = 
  &
    (1 - 4.5 w_1 - b)^2 + (1 - 16  w_1 - b)^2 + (1 - 9.8  w_1 - b)^2
  \\&
    + (0 - 0.46  w_1 - b)^2 + (0 - 7.2 w_1 - b)^2 + (0 - 5.7 w_1 - b)^2
\end{align*}

確かに、勾配が0に近くなる領域は、解を与える$b = -8.3w_1$の周辺だけであり、
勾配喪失問題は発生しないことが分かる。

\begin{figure}
  \centering
    \includegraphics[width=0.7\linewidth]{fig/1-dim-id-3d.pdf}

    (a) 3次元空間内での表現
    \vspace{5mm}

    \includegraphics[width=0.7\linewidth]{fig/1-dim-id-contour.pdf}
    
    (b) 等高線による表現

  \caption{恒等写像による損失関数}
\label{fig:identity-weight-bias}
\end{figure}

実は、
活性化関数に恒等関数を使うことにより、
計算上の大きなメリットも存在する。
具体的には、勾配ベクトルの成分$\frac{\partial L}{\partial w_1}$と
$\frac{\partial L}{\partial b}$を0にする点は、
連立一次方程式
\begin{align*}
  &
    \frac{\partial L}{\partial w_1} =
    87.32 b + 913.6632 w_1 - 60.6 = 0
  \\&
  \frac{\partial L}{\partial b} =
  12.0 b + 87.32 w_1 - 6.0 = 0
\end{align*}
を解くことによって求めることが可能で、実際、
\[
  w_1 \approx 0.061, \qquad b \approx 0.057
\]
が得られる。
計算時間が必要な勾配降下法を利用する必要がない。

しかしながら、
活性化関数に恒等関数を利用する設定には、致命的な問題がある。
活性化関数が入力に関して非線形関数
（入力数が1であるこの例では、定数$a, b$に対して$ax_1 + b$と表されない関数）であることが、
人工ニューラルネットが幅広い問題を解決することができるための条件であるからである。
この点については\ref{sec:universality}節で詳しく説明するが、
結果だけ述べると、
単層パーセプトロンは線形関数で表現される分離超平面を探索するが、
多層パーセプトロンでは非線形関数で表される分離「超曲面」を探索することを目指す。
多層パーセプトロンが非線形な分離「超曲面」を探索できるために必要な条件が、
\textbf{活性化関数が非線形関数}であることなのである。

ReLu（Rectified Linear Units）関数は、
\begin{itembox}{\bf ReLU関数}
\[
  \relu u = \max \{0, u\}
\]
\end{itembox}
と定義される。

図~\ref{fig:relu-weight-bias}に、
活性化関数にReLU関数を用いた場合の損失関数のグラフを示す。
$u < 0$でReLU関数の勾配が0になることから、
$b < -8.3 w_1$の領域で勾配が喪失されているが、
残りの領域では$b = -8.3w_1$に降りる方向に一貫した勾配が存在するので、
初期値が$b > -8.3w_1$の領域にあれば、
重みとバイアスの値は勾配降下法により確実に収束する。

\begin{figure}
  \centering
    \includegraphics[width=0.7\linewidth]{fig/1-dim-relu-3d.pdf}

    (a) 3次元空間内での表現
    \vspace{5mm}

    \includegraphics[width=0.7\linewidth]{fig/1-dim-relu-contour.pdf}
    
    (b) 等高線による表現

  \caption{ReLU関数による損失関数}
\label{fig:relu-weight-bias}
\end{figure}

ReLU関数は、$u < 0$において恒等的に0になり勾配が喪失してしまうという欠点に加えて、
$u = 0$で微分が出来ないという欠点もある。
これらの欠点を解決することを目的に、ReLU関数の派生となる関数が複数提案されているが、
2020年に提案されたMish関数は、全領域で難解でも微分が可能で、
また、実験で良好な性能を示していることから、今後利用が広まることが予想されている。
Mish関数は次の式で定義される。
\begin{itembox}{\bf Mish関数}
\[
  \mathrm{Mish}(u) = u \cdot \tanh\left(\log(1 + e^x)\right)
\]
\end{itembox}
図~\ref{fig:relu-mish}からMish関数はReLU関数を滑らかに近似する関数である事実を観察することができる。
$\tanh(u)$は双曲線正接関数である（\ref{sec:general}節を参照）。

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{fig/relu-mish.pdf}
  \caption{ReLU関数とMish関数}
  \label{fig:relu-mish}
\end{figure}

\subsubsection{まとめと一般形式}
\label{sec:general}

前節まででは、理解を容易にするため、
パーセプトロンは一つの入力$x_1$のみを受け取るものと仮定したが、
一般には、
パーセプトロンは任意個数の入力$x_1, \dots, x_d$を受け取り、単一の$y$を出力する。
これに伴い、重みも$w_1, \dots, w_d$と入力の個数だけ存在し、
入力の総量は重み付き和として計算される。
\begin{itembox}{\bf 入力の重み付き和}
  \[
    u = b + \sum_{i=1}^dn w_i x_i
  \]
\end{itembox}
入力の重み付き和$u$を出力$y$に変換する関数が活性化関数であり、
最初期のマカロック・ピッツモデルでは、
ヘヴィサイド階段関数$H_0(u)$が利用されたが、
損失関数の最小化を原理とする学習法の導入により、
$H_0(u)$の近似であり、また、計算が簡明なロジスティック関数$\logi u$が導入された。
更に、勾配喪失問題を回避するためにReLU関数や、その改良であるMesh関数が利用されている。
上記の他に、
\textbf{双曲線正接関数}（hyperbolic tangent function）も活性化関数として利用される。
\begin{itembox}{\bf 双曲線正接関数}
  \[
    \tanh u = \frac{e^u - e^{-u}}{e^u + e^{-u}}
    = 2\logi{2u} - 1
  \]
\end{itembox}
双曲線正接関数は、ロジスティック関数の座標を変換した関数で、本質的には同じものであるが、
$u < 0$で負の値をとる点に実用的なメリットが存在する。

活性化関数を一般に$f(u)$と表すと、パーセプトロンの出力$y$は次式で与えられる。
\begin{itembox}{\bf 出力}
  \[
    y = f(u) = f\left(b + \sum_{i=1}^d w_i x_i\right)
  \]
\end{itembox}

一方、代表的な損失関数は、残差平方和と交差エントロピーである。
訓練データセットが$n$個のデータ$\vc x[1], \dots, \vc x[n]$を含み、
対応するラベルを$t[1], \dots, t[n]$とする。
各データは$d$次元のベクトルであり、
$\vc x[i] = (x_1[i], \dots, x_d[i])$と表す。
損失関数は、各データ毎$\vc x[i]$に計算される出力$y[i]$と、（正しい）ラベル$t[i]$との乖離（損失）を、
全てのデータにわたって足し合わせたものと定義される。
\textbf{損失関数は重み$\boldsymbol{w_1, \dots, w_d}$と重み$\boldsymbol b$の関数}である。
\begin{itembox}{\bf 損失関数}
  \begin{description}
  \item[残差平方和：] $\displaystyle
    L(w_1, \dots, w_d, b) = \sum_{i=1}^n \left(t[i] - y[i]\right)^2$
  \item[交差エントロピー：] $\displaystyle
    L(w_1, \dots, w_d, b) = \sum_{i=1}^n
    \big(-t[i]\log y[i] - (1 - t[i])\log (1 - y[i])\big)$
  \end{description}
\end{itembox}

勾配降下法では、\textbf{勾配ベクトル$\boldsymbol{\nabla L(w_1, \dots, w_d, b)}$}を
\begin{itembox}{\bf 勾配ベクトル}
\[
  \nabla L(w_1, \dots, w_d, b) =
  \left(\frac{\partial L}{\partial w_1}, \dots, \frac{\partial L}{\partial w_d},
  \frac{\partial L}{\partial b}\right)
\]
\end{itembox}
により計算し、
勾配ベクトルに学習率$\eta$を乗じて、更新式
\begin{itembox}{\bf 勾配降下法の更新式}
\[
  (w_1, \dots, w_d, b) \leftarrow
  (w_1, \dots, w_d, b) - \eta \cdot \nabla L(w_1, \dots, w_d, b)
\]
\end{itembox}
により、損失関数を最小化するように重みとバイアスを逐次更新する。

活性化関数を一般的に$f(u)$、その導関数（微分）を$f'(u)$、
$\displaystyle u[i] = b + \sum_{j=1}^d w_j x_j[i]$と表す時、
損失関数の勾配ベクトルは次のように計算される。
\begin{itembox}{\bf 残差平方和の勾配ベクトル}
  \begin{align*}
    &
    \frac{\partial L}{\partial w_j} = (-2) \cdot \sum_{i=1}^n
    \left(t[i] - y[i]\right) f'(u[i]) x_j[i]
    \\&
    \frac{\partial L}{\partial b} = (-2) \cdot \sum_{i=1}^n
    \left(t[i] - y[i]\right) f'(u[i])
  \end{align*}
\end{itembox}

一方、交差エントロピーでは、出力$y[i]$が確率と解釈できることが必要で、
そのため、ロジスティック関数$\logi u$を活性化関数として使用されることが多い。
この組み合わせに対する損失関数の勾配ベクトルは次のように計算される。
\begin{itembox}{\bf 交差エントロピーの勾配ベクトル}
  \begin{align*}
    &
    \frac{\partial L}{\partial w_j} = \sum_{i=1}^n \left(-t[i] + \logi u\right)x_j[i]
    \\&
    \frac{\partial L}{\partial b} = \sum_{i=1}^n \left(-t[i] + \logi u\right)
  \end{align*}
\end{itembox}

最後に、ラベルが二値（0と1）ではなく、
多値（$\ell_1$から$\ell_l$までの$l$個）の場合の取り扱いについて説明する。
ここでは、
\textbf{$l$個のパーセプトロン$P_1, \dots, P_l$を用意し、
それぞれの$P_k$にラベル$\ell_k$を個別に学習させる}
手法を説明する。

訓練データはこれまでと同様に$\vc x[1], \dots \vc x[n]$とするが、
ラベルが0か1の二値を取る場合と異なり、
対応するラベル$\ell[1], \dots, \ell[n]$のそれぞれは
$\ell_1, \dots, \ell_l$のいずれかである。
一方、$P_k$の学習には0か1の値をとるラベル$t_k[1], \dots, t_k[n]$が必要なので、
ここでは、
$\ell[1], \dots, \ell[n]$を
$(t_1[1], \dots, t_l[1]), \dots, (t_1[n], \dots, t_l[n])$に変換する
\textbf{ワンホット符号化}という手法を説明する。
ワンホット符号化は、統計や機械学習で普遍的に利用される手法であり、
理解しておけば役に立つ。
\begin{itembox}{\bf ワンホット符号}
  ラベル集合$\{\ell_1, \dots, \ell_l\}$の各要素$\ell_k$を以下のように$l$次元ベクトルで表現する。
  \[
    \ell_k = (\underbrace{0, \dots, 0}_{\text{$k-1$個}}, 1,
    \underbrace{0, \dots, 0}_{\text{$l-k$個}})
  \]
  
\end{itembox}

\subsection{階層型ニューラルネットモデルの万能性}
\label{sec:universality}

誤り訂正学習では、訓練データが線形

損失関数に基づく学習により、
訓練データが線形分離
パーセプトロン